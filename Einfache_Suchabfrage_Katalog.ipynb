{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d0d72cd5-034d-4b94-a4e2-54f7753cb9f0"
    }
   },
   "source": [
    "# Einfache Suche im Bibliothekskatalog der *Zentralbibliothek Zürich*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zürich | 5. Mai 2023 - Linda Samsinger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Zentralbibliothek Zürich ist eine der grössten Bibliotheken in der Schweiz und stellt eine breite Palette von Sammlungen, darunter Bücher, Zeitschriften, Audio- und Videomaterialien zur Verfügung. Die ZB Zürich hat Zugriff auf den SLSP-Bibliothekskatalog, welcher Informationen zu allen in Schweizer Bibliotheken verfügbaren Medien enthält.  \n",
    "\n",
    "Dieses Jupyter Notebook beinhaltet Textanweisungen und Code-Blöcke zur fachkundigen **Abfrage des SLSP-Katalogs mit Suchbegriffen** und dem **Export des Suchresultats** als Excel, CSV oder JSON-Datei. Es erlaubt Ihnen, gezielt nach Medien zu suchen, welche Ihren spezifischen Interessen und Anforderungen entsprechen. \n",
    "\n",
    "Dank diesem Tutorial können **bis zu 10'000 Suchresultate** heruntergeladen werden im Vergleich zur Suchabfrage auf der [Swisscovery-Webseite der UB und ZB Zürich](https://uzb.swisscovery.slsp.ch/discovery/search?vid=41SLSP_UZB:UZB), die es nur erlaubt maximal 50 Suchresultate zu exportieren. Zudem liegen die Suchresultate flach strukturiert und auf einer einzigen Seite übersichtlich vor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Über dieses Jupyter Notebook werden nach **Eingabe von Suchbegriffen** im schweizweiten Netzwerk des SLSP-Bibliothekskatalogs  **alle bibliographischen Felder** nach entsprechenden Medien durchsucht. In der **Ausgabe enthalten sind die folgenden Felder**: Titel, Autor, Verlag, Publikationsort, Erscheinungsdatum, Auflage, physische Beschreibung, Sprache, Land, geographisches Thema, Form/Genre, Ressourcentyp, Thema, Zusammenfassung, Epoche, MMS-ID, ISBN, Swisscovery-Link und der Inhaltsverzeichnis-Link, falls vorhanden.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projektidee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mit diesem Notebook können Sie..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **schweizweite Katalogdaten als Grundlage für die akademische Forschungsarbeit beziehen** \n",
    "- **Medien der Bibliotheken über Swisscovery-Links einfach bestellen und ausleihen**\n",
    "- **PDFs über die Inhaltsverzeichnis-Links in der Ergebnisdatei herunterladen**\n",
    "- **statistische Analysen von Katalogdaten durchführen.**\n",
    "\n",
    "Für eine weitere Auflistung von Vorteilen für den Benutzer siehe Sektion [Nachnutzung der Ergebnisse](#nachnutzung) weiter unten. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ziel des Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![resultat](screenshot_suchresultat.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download](screenshot_download.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quelle: Der SLSP-Bibliothekskatalog "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ee78241c-36e7-45e6-b015-0ef46f1e777d"
    }
   },
   "source": [
    "Die Suchabfrage über den ganzen **SLSP-Bibliothekskatalog** von **über 25 Millionen Einträgen** schweizweit ist über die [Search/Retrieve-URL (SRU)-Schnittstelle (Version 1.2)](https://data.zb.uzh.ch/map/books/data-map-der-zentralbibliothek-zurich/page/alma-sru) der ZB Zürich verfügbar. Der SLSP-Bibliothekskatalog, der mithilfe dieses Jupyter Notebooks abgefragt wird, ist Teil des allgemein genutzten [Swisscovery-Katalog](https://uzb.swisscovery.slsp.ch/discovery/search?vid=41SLSP_UZB:UZB), welcher allerdings über noch mehr Datenzuflüsse verfügt. \n",
    "- Datenquelle: https://data.zb.uzh.ch/map/books/data-map-der-zentralbibliothek-zurich/page/alma-sru\n",
    "- Datenformat: [MARCXML](https://www.loc.gov/standards/marcxml//)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='konfiguration_der_suchabfrage'></a>\n",
    "## Konfiguration der Suchabfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eingabe der Suchkriterien"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Führen Sie den nachstehenden Code-Block aus: \"Ctrl\" + \"Enter\" (oder Klick auf das Run-Stopp-Zeichen des Code-Blocks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4711d886004b4b59820402cfc7549d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Stichwort: ', layout=Layout(align_items='center', display='flex', flex_flow='row',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets \n",
    "from ipywidgets import Layout\n",
    "\n",
    "# Widget \"Suchbox\" anzeigen \n",
    "form_item_layout = Layout(\n",
    "    display='flex',\n",
    "    flex_flow='row',\n",
    "    justify_content='space-around', \n",
    "    width='50%'\n",
    "    , grid_area='sidebar', align_items = 'center'\n",
    ")\n",
    "\n",
    "text = widgets.Text(\n",
    "    placeholder='z.B. nach \"Geschichte alt* Ägypten\" im SLSP-Katalog',\n",
    "    description='Stichwort: ',\n",
    "    disabled=False\n",
    "    , layout=form_item_layout\n",
    ")\n",
    "\n",
    "display(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geben Sie Ihren Suchbegriff in die Suchbox ein.** Der Suchbegriff wird mit der \"Enter\"-Taste gespeichert.\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tipp:</b> Ein möglicher Suchbegriff für den SLSP-Bibliothekskatalog ist der Titel eines Buches, der für Ihre Forschung relevant sein könnte. Ein weiterer möglicher Suchbegriff wäre der Autor eines Buches oder der Artikel, den Sie benötigen. Andere mögliche Suchbegriffe sind Themenbegriffe oder Schlagworte, die mit Ihrem Forschungsinteresse zuammenhängen, oder Erscheinungsjahr und Sprache. Basierend auf dem Suchbegriff wird eine einfache Suchabfrage gestartet, die alle bibliografischen Felder durchsucht. </div>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Klick auf \"Run All Below\"**: Ab dieser Konfigurationsstelle kann der ganze verbleibende Code in einem Zug durchgespielt werden. Klicken Sie dazu auf den darunter stehenden Code-Block, dann im Navigationsmenu auf \"Cell\" und dann auf \"Run All Below\", um alle Code-Blöcke auf einmal auszuführen. Die Ausführung kann je nach Anzahl der gefundenen Ergebnisse unterschiedlich lang dauern.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import der Programmabhängigkeiten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im folgenden Code-Block werden die benutzten Programmmodule importiert oder bei Bedarf installiert: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module installieren \n",
    "#!pip install virtualenv\n",
    "#!virtualenv pymarc_env\n",
    "#!.\\pymarc_env\\Scripts\\activate\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saml\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (2.0.2) or chardet (4.0.0)/charset_normalizer (2.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Module importieren \n",
    "import requests, os\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from lxml import etree\n",
    "import pandas as pd\n",
    "import xmltodict\n",
    "import pymarc\n",
    "from IPython.display import display, HTML, Javascript \n",
    "from tqdm import tqdm\n",
    "import functools as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zusätzlich zu den Python-Modulen braucht es noch folgende Dateien im Jupyter Notebook-Verzeichnis: \n",
    "- `screenshot_suchresultat.png`\n",
    "- `screenshot_download.png`\n",
    "- `lang_dict.xlsx`\n",
    "- `country_dict.xlsx`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='durchführung_der_suchabfrage'></a>\n",
    "## Durchführung der Suchabfrage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laden von externen Listen und Funktionen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprachen \n",
    "df = pd.read_excel(r'lang_dict.xlsx')\n",
    "lang_dict = dict(zip(df.LangCode, df.LangDe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lang(lang_value): \n",
    "    sprach_value = ''\n",
    "    for key, value in lang_dict.items(): \n",
    "        if key == lang_value: \n",
    "            if value == 'None': \n",
    "                sprach_value = None \n",
    "            else: \n",
    "                sprach_value = value \n",
    "\n",
    "    return sprach_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Länder\n",
    "df = pd.read_excel(r'country_dict.xlsx')\n",
    "ctry_dict = dict(zip(df.CountryCode, df.CountryDe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country(country_code): \n",
    "    country_value = ''\n",
    "    for key, value in ctry_dict.items(): \n",
    "        if key == country_code:\n",
    "            if value == 'None': \n",
    "                country_value = None \n",
    "            else: \n",
    "                country_value = value \n",
    "\n",
    "    return country_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epoche\n",
    "def get_epoch(lebens_value):\n",
    "    if type(lebens_value) == int: \n",
    "        if lebens_value <500: \n",
    "            epoche_value = 'Antike'\n",
    "        elif lebens_value <1492: \n",
    "            epoche_value = 'Mittelalter'\n",
    "        elif lebens_value <1914: \n",
    "            epoche_value = 'Neuzeit'\n",
    "        else: \n",
    "            epoche_value = 'Gegenwart'\n",
    "    else: \n",
    "        epoche_value = None\n",
    "    return epoche_value     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ressourcentyp \n",
    "pubart_dict = {'a': 'Sprachmaterial', \n",
    "            'c': 'Noten', \n",
    "            'd': 'Noten',\n",
    "            'e': 'Karte', \n",
    "            'f': 'Karte',\n",
    "            'g': 'Projektionsmedium', \n",
    "            'i': 'Tonaufnahme', \n",
    "            'j': 'Tonaufnahme',\n",
    "            'k': 'Grafik', \n",
    "            'm': 'Computerdatei',\n",
    "            'o': 'Satz', \n",
    "            'p': 'Gemischt', \n",
    "            'r': 'Artefakt',\n",
    "            't': 'Sprachmaterial'} \n",
    "\n",
    "def get_pubart(pubart_value): \n",
    "    pbrt_value = ''\n",
    "    for key, value in pubart_dict.items(): \n",
    "        if key == str(pubart_value): \n",
    "            pbrt_value = value \n",
    "\n",
    "    return pbrt_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubart2_dict = {'a': 'Monographie', \n",
    "            'b': 'Zeitschrift', \n",
    "            'c': 'Sammlung',\n",
    "            'd': 'Untereinheit', \n",
    "            'i': 'Integrierende Ressource',\n",
    "            'm': 'Einzeldarstellung', \n",
    "            's': 'Zeitschrift'} \n",
    "\n",
    "def get_pubart2(pubart2_value): \n",
    "    pbrt2_value = ''\n",
    "    for key, value in pubart2_dict.items(): \n",
    "        if key == str(pubart2_value): \n",
    "            pbrt2_value = value \n",
    "\n",
    "    return pbrt2_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pubart3(pubart3_value): \n",
    "    pbrt3_value = ''\n",
    "    if pubart3_value == 'o' or pubart3_value == 'q' or pubart3_value == 's': \n",
    "        pbrt3_value = \"elektronisch\" \n",
    "    else: \n",
    "        pbrt3_value = \"physisch\"\n",
    "    return pbrt3_value   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiederholbare Felder \n",
    "def get_repeatable_field_value(record, field_no, field_sub, sep=\";\"): \n",
    "        repeatable_field_value = \"\"\n",
    "        if len(record.get_fields(field_no)) != 0:\n",
    "            for el in range(len(record.get_fields(field_sub))):\n",
    "                try:\n",
    "                    if record.get_fields(field_no)[el][field_sub]!= None:\n",
    "                        repeatable_field_val = record.get_fields(field_no)[el][field_sub]            \n",
    "                        repeatable_field_value += sep + repeatable_field_val \n",
    "                except: \n",
    "                    continue\n",
    "        else: \n",
    "            repeatable_field_value = None \n",
    "        try: \n",
    "            repeatable_field_value = repeatable_field_value[1:]\n",
    "        except: \n",
    "            repeatable_field_value = None\n",
    "        return repeatable_field_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feldwerte\n",
    "def get_record_value(record, field_no, field_sub): \n",
    "    record_value = \"\"\n",
    "    try: \n",
    "        record_value = record.get_fields(field_no)[0][field_sub]\n",
    "    except: \n",
    "        pass\n",
    "    return record_value "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition der Ausgabefelder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# durchsuchbare Felder\n",
    "titel_no = '245' #Titel-MARC\n",
    "titel_sub = 'a' #Titel-MARC (Haupttitel)\n",
    "titel_sub2 = 'b' #Titel-MARC (Untertitel)\n",
    "autor_no = '100' #Autor-MARC \n",
    "autor_sub = 'a' #Autor-MARC \n",
    "autor2_no = '700' #Weitere Autoren-MARC  \n",
    "autor2_sub1 = 'a' #Weitere Autoren-MARC  \n",
    "autor2_sub2 = '4' #Weitere Autoren-MARC \n",
    "editor_no = '700' #Editoren-MARC \n",
    "editor_sub1 = 'a' #Editoren-MARC\n",
    "editor_sub2 = '4' #Editoren-MARC\n",
    "editor_sub3 = 'e'  #Editoren-MARC\n",
    "verlag_no = '264' #Verlag-MARC\n",
    "verlag_sub = 'b' #Verlag-MARC\n",
    "pubort_no = '260' #Publikationsort-MARC\n",
    "pubort_sub = 'a' #Publikationsort-MARC\n",
    "pubort_no2 = '264' #Publikationsort-MARC\n",
    "pubort_sub2 = 'a' #Publikationsort-MARC\n",
    "erschdat_no = '260' #Erscheinungsdatum-MARC\n",
    "erschdat_sub = 'c' #Erscheinungsdatum-MARC\n",
    "erschdat_no2 = '264' #Erscheinungsdatum-MARC\n",
    "erschdat_sub2 = 'c' #Erscheinungsdatum-MARC\n",
    "erschdat_no3 = '008' #Erscheinungsdatum-MARC\n",
    "thema_no = '650' #Thema-MARC\n",
    "thema_sub = 'a' #Thema-MARC\n",
    "sprache_no = '008' #Sprache-MARC\n",
    "land_no = '008' #Land-MARC\n",
    "geo_no = '651' #Geographisches-Thema-MARC\n",
    "geo_sub = 'a' #Geographisches-Thema-MARC\n",
    "auflage_no = '250' #Auflage-MARC\n",
    "auflage_sub = 'a' #Auflage-MARC\n",
    "zus_no = '520' #Zusammenfassung-MARC\n",
    "zus_sub = 'a' #Zusammenfassung-MARC\n",
    "genr_no = '655' #Form/Genre-MARC\n",
    "genr_sub = 'a' #Form/Genre-MARC\n",
    "beschr_no = '300' #Beschreibung-MARC\n",
    "beschr_sub = 'a' #Beschreibung-MARC\n",
    "pubart3_no = '008' #Ressourcentyp-MARC\n",
    "authyear_no = '100' #Epoche-MARC\n",
    "authyear_sub = 'd' #Epoche-MARC\n",
    "authyear2_no = '700' #Epoche-MARC\n",
    "authyear2_sub = 'd' #Epoche-MARC\n",
    "\n",
    "# nichtdurchsuchbare Felder \n",
    "mms_id_no = '001' #MMS-ID-MARC\n",
    "isbn_no = '020' #ISBN-MARC\n",
    "isbn_sub = 'a' #ISBN-MARC\n",
    "ilink_no = '856' #Swisscovery-MARC\n",
    "ilink_sub = 'u' #Swisscovery-MARC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Öffnen der Suchseite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es wurden  196  Ergebnisse gefunden. Hinweis: Je mehr Ergebnisse vorhanden sind, desto länger dauert das Herunterladen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saml\\Anaconda3\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Suchbegriff evaluieren\n",
    "keyword = text.value\n",
    "replacements = str.maketrans({'ä': 'ae', 'ö': 'oe', 'ü':'ue', 'Ä':'Ae','Ö':'Oe', 'Ü': 'Ue', 'è': 'e', 'é':'e'})\n",
    "keyword = keyword.translate(replacements)\n",
    "\n",
    "# URL-Suchabfrage starten \n",
    "base_url = \"https://slsp-network.alma.exlibrisgroup.com/view/sru/41SLSP_NETWORK?version=1.2&operation=searchRetrieve&recordSchema=marcxml&query=all_for_ui%20all%20%22\" + keyword + \"%22&startRecord=0\"\n",
    "base_url = base_url.replace(\" \", \"%20\")\n",
    "\n",
    "params = {'recordSchema' : 'marcxml',\n",
    "      'operation': 'searchRetrieveResponse',\n",
    "      'version': '1.2'\n",
    "     }\n",
    "r = requests.get(base_url, params=params)\n",
    "\n",
    "#Suchergebnis analysieren\n",
    "xml = soup(r.content, \"lxml\")\n",
    "no_records = int(xml.find('numberofrecords').text)\n",
    "\n",
    "print('Es wurden ', str(no_records+1), ' Ergebnisse gefunden. Hinweis: Je mehr Ergebnisse vorhanden sind, desto länger dauert das Herunterladen.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ausführung der Suche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [00:23,  8.36it/s]                                                                                               \n"
     ]
    }
   ],
   "source": [
    "# Seitenindex\n",
    "timeout_page = 0 # die Zahl ersetzen, falls das Herunterladen unterbrochen wurde, siehe #print(nextpage)\n",
    "if timeout_page > 0: \n",
    "    timeout_page += 1 \n",
    "nextpage = 0 + timeout_page\n",
    "results_dict = {}\n",
    "\n",
    "# Ladebalken \n",
    "pbar = tqdm(total = int(no_records))\n",
    "\n",
    "# Iteration über alle Webseiten der URL mit den Suchergebnissen \n",
    "while nextpage < no_records:\n",
    "    next_url = base_url[:-1] + str(nextpage + timeout_page)\n",
    "    response = requests.get(next_url)\n",
    "    dict_data = xmltodict.parse(response.content)\n",
    "    records = pymarc.parse_xml_to_array(next_url, strict=True)\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        try: \n",
    "            index = int(dict_data['searchRetrieveResponse']['records']['record']['recordPosition'])\n",
    "        except: \n",
    "            index = int(dict_data['searchRetrieveResponse']['records']['record'][i]['recordPosition'])\n",
    "            \n",
    "        # durchsuchbare Felder:    \n",
    "\n",
    "        # Titel \n",
    "        titel_value = \"\"\n",
    "        if len(record.get_fields(titel_no)) != 0: \n",
    "            titel_value = get_record_value(record, titel_no, titel_sub)  \n",
    "            titel_value2 = get_record_value(record, titel_no, titel_sub2)\n",
    "            if titel_value2: \n",
    "                titel_value = ', '.join(filter(None, [titel_value, titel_value2]))\n",
    "        else: \n",
    "            titel_value = None \n",
    "        if titel_value != None and len(titel_value) > 1:\n",
    "            titel_value = titel_value.replace(\"[\", \"\")\n",
    "            titel_value = titel_value.replace(\"]\", \"\")\n",
    "            titel_value = titel_value.replace(\"<<\", \"\")\n",
    "            titel_value = titel_value.replace(\">>\", \"\")\n",
    "            if titel_value[-1] == \"/\" or titel_value[-1] == \".\": \n",
    "                titel_value = titel_value[:-1]\n",
    "        \n",
    "        # Autor\n",
    "        autor_value = \"\"\n",
    "        vorname_value = \"\"\n",
    "        nachname_value = \"\"\n",
    "        if len(record.get_fields(autor_no)) != 0: \n",
    "            autor_value = get_record_value(record, autor_no, autor_sub)              \n",
    "        else: \n",
    "            autor_value = None\n",
    "        if autor_value != None and len(autor_value) > 1:  \n",
    "            if autor_value[-1] == \",\" or (autor_value[-1] == \".\" and not type(autor_value[-2]) == str): \n",
    "                autor_value = autor_value[:-1]\n",
    "            autor_value = autor_value.strip()    \n",
    "            autor_lst = autor_value.split(',')\n",
    "            try: \n",
    "                vorname_value, nachname_value = autor_lst[1].strip(), autor_lst[0].strip()\n",
    "            except: \n",
    "                nachname_value = autor_lst[0]\n",
    "                vorname_value = None\n",
    "        \n",
    "        # Weitere Autoren\n",
    "        autor2_values = \"\"\n",
    "        autor2_lst2 = []\n",
    "        if len(record.get_fields(autor2_no)) != 0: \n",
    "            for el in range(len(record.get_fields(autor2_no))):\n",
    "                if get_record_value(record, autor2_no, autor2_sub2)  == 'aut': \n",
    "                    autor2_value = record.get_fields(autor2_no)[el][autor2_sub1]   \n",
    "                    autor2_values += \"; \" +  autor2_value \n",
    "        else: \n",
    "            autor2_values = None\n",
    "        if autor2_values!= None and len(autor2_values) > 1: \n",
    "            if autor2_values[0] == \";\": \n",
    "                autor2_values = autor2_values[1:].strip()\n",
    "            autor2_lst = [ el.split(\",\") for el in [el.strip()  for el in autor2_values.split(';') if el != '']] \n",
    "            for el in autor2_lst:\n",
    "                try: \n",
    "                    el[0], el[1] = el[1], el[0]\n",
    "                    autor2_names = el[0].strip() + ' ' + el[1].strip()\n",
    "                    autor2_lst2.append(autor2_names)\n",
    "                except: \n",
    "                    autor2_lst2.append(el[0])\n",
    "            autor2_values =  '; '.join(autor2_lst2) \n",
    "\n",
    "        \n",
    "        # Editoren\n",
    "        editor_values = \"\"\n",
    "        editor_lst2 = []\n",
    "        if len(record.get_fields(editor_no)) != 0: \n",
    "            for el in range(len(record.get_fields(editor_no))):\n",
    "                if get_record_value(record, editor_no, editor_sub2)  == 'edt': \n",
    "                    editor_value = record.get_fields(editor_no)[el][editor_sub1]   \n",
    "                    editor_values += \"; \" +  editor_value \n",
    "                try: \n",
    "                    if 'editor' in get_record_value(record, editor_no, editor_sub3): \n",
    "                        editor_value = record.get_fields(editor_no)[el][editor_sub1]   \n",
    "                        editor_values += \"; \" +  editor_value \n",
    "                except: \n",
    "                    continue\n",
    "        else: \n",
    "            editor_values = None\n",
    "        if editor_values!= None and len(editor_values) > 1: \n",
    "            if editor_values[0] == \";\": \n",
    "                editor_values = editor_values[1:].strip()\n",
    "            editor_lst = [el.split(\",\") for el in [el.strip() for el in editor_values.split(';') if el != '']]\n",
    "            for el in editor_lst: \n",
    "                try: \n",
    "                    el[0], el[1] = el[1], el[0]\n",
    "                    editor_lst = el[0].strip() + ' ' + el[1].strip()\n",
    "                    editor_lst2.append(editor_lst)\n",
    "                except: \n",
    "                    editor_lst2.append(el[0])\n",
    "                editor_values =  '; '.join(editor_lst2)\n",
    "    \n",
    "        # Verlag\n",
    "        verlag_value = get_repeatable_field_value(record, verlag_no, verlag_sub)\n",
    "        if verlag_value != None and len(verlag_value) > 1:\n",
    "            if verlag_value[-1] == \",\" or verlag_value[-1] == \":\": \n",
    "                verlag_value = verlag_value[:-1]\n",
    "            verlag_value = verlag_value.replace(\"[\", \"\")\n",
    "            verlag_value = verlag_value.replace(\"]\", \"\")\n",
    "            verlag_value = verlag_value.replace(\"?\", \"\")\n",
    "            verlag_value = verlag_value.strip() \n",
    "            \n",
    "        # Publikationsort\n",
    "        pubort_value = \"\"\n",
    "        if len(record.get_fields(pubort_no)) != 0:\n",
    "            for el in range(len(record.get_fields(pubort_no))):\n",
    "                try: \n",
    "                    if record.get_fields(pubort_no)[el][pubort_sub]!= None:\n",
    "                        pubort_val = record.get_fields(pubort_no)[el][pubort_sub]            \n",
    "                        pubort_value += \";\" + pubort_val   \n",
    "                except: \n",
    "                    continue\n",
    "        else: \n",
    "            pubort_value = \"\"\n",
    "            if len(record.get_fields(pubort_no2)) != 0:\n",
    "                for el in range(len(record.get_fields(pubort_no2))):\n",
    "                    if get_record_value(record, pubort_no2, pubort_sub2)!= None:\n",
    "                        pubort_val = get_record_value(record, pubort_no2, pubort_sub2)           \n",
    "                        pubort_value += \";\" + pubort_val     \n",
    "            else: \n",
    "                pubort_value = None \n",
    "            try: \n",
    "                pubort_value = pubort_value[1:]\n",
    "            except: \n",
    "                pubort_value = None \n",
    "        if pubort_value != None and len(pubort_value) > 1:\n",
    "            if pubort_value[0] == \";\" or pubort_value[0] == \",\" : \n",
    "                pubort_value = pubort_value[1:]\n",
    "            if pubort_value[-1] == \":\" or pubort_value[-1] == \";\": \n",
    "                pubort_value = pubort_value[:-1]\n",
    "            if type(pubort_value) == int: \n",
    "                pubort_value = None \n",
    "            pubort_value = pubort_value.replace(\"[\", \"\")\n",
    "            pubort_value = pubort_value.replace(\"]\", \"\")\n",
    "            pubort_value = pubort_value.replace(\"?\", \"\")\n",
    "            pubort_value = pubort_value.strip()\n",
    "            if pubort_value.isdigit():\n",
    "                pubort_value = None\n",
    "      \n",
    "         # Erscheinungsjahr\n",
    "        erschdat_value = \"\"\n",
    "        if len(record.get_fields(erschdat_no)) != 0:\n",
    "            for el in range(len(record.get_fields(erschdat_no))):\n",
    "                try: \n",
    "                    if record.get_fields(erschdat_no)[el][erschdat_sub]!= None:\n",
    "                        erschdat_val = record.get_fields(erschdat_no)[el][erschdat_sub]            \n",
    "                        erschdat_value += \";\" + erschdat_val \n",
    "                except: \n",
    "                    continue\n",
    "        else: \n",
    "            erschdat_value = \"\"\n",
    "            if len(record.get_fields(erschdat_no2)) != 0:\n",
    "                for el in range(len(record.get_fields(erschdat_no2))):\n",
    "                    if get_record_value(record, erschdat_no2, erschdat_sub2)!= None:\n",
    "                        erschdat_val = get_record_value(record, erschdat_no2, erschdat_sub2)            \n",
    "                        try: \n",
    "                            if erschdat_val[-1] == \".\": \n",
    "                                erschdat_val = erschdat_val[:-1]\n",
    "                            erschdat_value += \";\" + erschdat_val \n",
    "                        except: \n",
    "                            continue\n",
    "            else: \n",
    "                if len(record.get_fields(erschdat_no3)) != 0:\n",
    "                    erschdat_value = record.get_fields(erschdat_no3)[0].value()[6:11]            \n",
    "                else: \n",
    "                    erschdat_value = None \n",
    "        if erschdat_value != None and len(erschdat_value) > 1:  \n",
    "            if erschdat_value[0] == \";\": \n",
    "                erschdat_value = erschdat_value[1:]\n",
    "            if erschdat_value[-1] == \".\": \n",
    "                erschdat_value = erschdat_value[:-1]\n",
    "            erschdat_value = erschdat_value.replace(\"[\", \"\")\n",
    "            erschdat_value = erschdat_value.replace(\"]\", \"\")\n",
    "            erschdat_value = erschdat_value.replace(\"©\", \"\")\n",
    "            erschdat_value = erschdat_value.replace(\"℗\", \"\")\n",
    "            erschdat_value = erschdat_value.replace(\"?\", \"\")\n",
    "            erschdat_lst = erschdat_value.split(\";\")\n",
    "            erschdat_lst = [el.strip() for el in erschdat_lst] \n",
    "            for i, el in enumerate(erschdat_lst):  \n",
    "                try: \n",
    "                    if el[1].isdigit() and el[0].isalpha(): \n",
    "                        el = el.replace(el[0], \"\")\n",
    "                        erschdat_lst[i] = el\n",
    "                except: \n",
    "                    continue\n",
    "            erschdat_value = ';'.join(list(set(erschdat_lst)))\n",
    "            erschdat_value = erschdat_value.strip()\n",
    "        try: \n",
    "            if 'X' in erschdat_value or 'I' in erschdat_value or 'M' in erschdat_value or 'L' in erschdat_value or 'V' in erschdat_value: \n",
    "                erschdat_value = erschdat_value\n",
    "            else: \n",
    "                if 'J' not in erschdat_value: \n",
    "                    erschdat_lst = erschdat_value.split(\" \")\n",
    "                    erschdat_lst = [el for el in erschdat_lst if el.isdigit() or el[0].isdigit() or el[1].isdigit() or el[2].isdigit()]\n",
    "                    erschdat_value = ';'.join(list(dict.fromkeys(erschdat_lst)))\n",
    "                else: \n",
    "                    erschdat_value = erschdat_value\n",
    "        except: \n",
    "            pass   \n",
    "            \n",
    "        # Auflage   \n",
    "        auflage_value = get_repeatable_field_value(record, auflage_no, auflage_sub)\n",
    "        if auflage_value != None and len(auflage_value) > 1: \n",
    "            auflage_value = auflage_value.replace(\"[\", \"\")\n",
    "            auflage_value = auflage_value.replace(\"]\", \"\")\n",
    "        \n",
    "        # Physische Beschreibung\n",
    "        beschr_value = get_repeatable_field_value(record, beschr_no, beschr_sub)\n",
    "            \n",
    "        # Sprache\n",
    "        if len(record.get_fields(sprache_no)) != 0:\n",
    "            lang_value = record.get_fields(sprache_no)[0].value()[35:38] \n",
    "            if get_lang(lang_value) or get_lang(lang_value) == None: \n",
    "                lang_value = get_lang(lang_value)\n",
    "        else: \n",
    "            lang_value = None \n",
    "            \n",
    "        # Land\n",
    "        if len(record.get_fields(land_no)) != 0:\n",
    "            ctry_value = record.get_fields(land_no)[0].value()[15:18]\n",
    "            ctry_value = ctry_value.strip()\n",
    "            if get_country(ctry_value) or get_country(ctry_value) == None: \n",
    "                ctry_value = get_country(ctry_value)\n",
    "        else: \n",
    "            ctry_value = None \n",
    "        \n",
    "        # Geographisches Thema\n",
    "        geo_value = get_repeatable_field_value(record, geo_no, geo_sub)      \n",
    "        if geo_value != None and len(geo_value) > 1: \n",
    "            geo_value = geo_value.replace(\"[\", \"\")\n",
    "            geo_value = geo_value.replace(\"]\", \"\")\n",
    "            if geo_value[-1] == \".\" or geo_value[-1] == \";\": \n",
    "                geo_value = geo_value[:-1]\n",
    "            geo_value = geo_value.strip()\n",
    "            \n",
    "        # Form/Genre\n",
    "        genr_value = get_repeatable_field_value(record, genr_no, genr_sub)\n",
    "        if genr_value != None and len(genr_value) > 1:  \n",
    "            if genr_value[0] == \";\": \n",
    "                genr_value = genr_value[1:]\n",
    "            if genr_value[-1] == \".\": \n",
    "                genr_value = genr_value[:-1]\n",
    "            genr_value = genr_value.replace(\"[\", \"\")\n",
    "            genr_value = genr_value.replace(\"]\", \"\")\n",
    "            genr_lst = genr_value.split(\";\")\n",
    "            genr_lst = [el.strip() for el in genr_lst]\n",
    "            genr_value = ';'.join(list(set(genr_lst)))\n",
    "            genr_value = genr_value.strip()     \n",
    "        \n",
    "        #Ressourcentyp \n",
    "        if len(record.leader) != 0:\n",
    "            pubart_value = record.leader[6] \n",
    "            if get_pubart(pubart_value) or get_pubart(pubart_value) == None: \n",
    "                pubart_value = get_pubart(pubart_value)\n",
    "        else: \n",
    "            pubart_value = None \n",
    "     \n",
    "        if len(record.leader) != 0:\n",
    "            pubart2_value = record.leader[7] \n",
    "            if get_pubart2(pubart2_value) or get_pubart2(pubart2_value) == None: \n",
    "                pubart2_value = get_pubart2(pubart2_value)\n",
    "        else: \n",
    "            pubart2_value = None \n",
    "   \n",
    "        if len(record.get_fields(pubart3_no)) != 0:\n",
    "            try: \n",
    "                pubart3_value = record.get_fields(pubart3_no)[0].value()[23]\n",
    "            except: \n",
    "                pubart3_value = record.get_fields(pubart3_no)[0].value()[29]\n",
    "            if get_pubart3(pubart3_value) or get_pubart3(pubart3_value) == None: \n",
    "                pubart3_value = get_pubart3(pubart3_value)\n",
    "        else: \n",
    "            pubart3_value = None \n",
    "              \n",
    "        if pubart_value == 'Sprachmaterial' and (pubart2_value == 'Einzeldarstellung' or pubart2_value == 'Untereinheit' or pubart2_value == 'Sammlung' or pubart2_value == 'Monographie'): \n",
    "            publart_value = 'Buch' + ' - ' + pubart3_value\n",
    "        elif pubart_value == 'Sprachmaterial' and (pubart2_value == 'Integrierende Ressource' or pubart2_value == 'Zeitschrift'): \n",
    "            publart_value = 'Zeitschrift'  + ' - ' + pubart3_value\n",
    "        elif (pubart_value == 'Gemischt' or pubart_value == 'Satz' or pubart_value == 'Artefakt'): \n",
    "            publart_value = 'Gemischtes Material' + ' - ' + pubart3_value\n",
    "        elif pubart_value != 'Sprachmaterial' or pubart_value != 'Gemischt' or pubart_value != 'Satz' or pubart_value != 'Artefakt':    \n",
    "            publart_value = pubart_value + ' - ' + pubart3_value\n",
    "        else: \n",
    "            publart_value = None\n",
    "\n",
    "            \n",
    "        # Thema  \n",
    "        thema_value = get_repeatable_field_value(record, thema_no, thema_sub, sep=\" \") \n",
    "        if thema_value != None and len(thema_value) > 1: \n",
    "            thema_lst = thema_value.split(\" \")\n",
    "            thema_lst = [el.strip() for el in thema_lst if el != '']\n",
    "            thema_value = ' '.join(list(dict.fromkeys(thema_lst)))\n",
    "            thema_value = thema_value.strip()\n",
    "        \n",
    "        # Zusammenfassung\n",
    "        zus_value = get_repeatable_field_value(record, zus_no, zus_sub, sep=\" \") \n",
    "         \n",
    "        \n",
    "        # Epoche\n",
    "        epoche_value = \"\"\n",
    "        epoche_all = \"\"\n",
    "        try:\n",
    "            authyear_value = record.get_fields(authyear_no)[0][authyear_sub] \n",
    "            if authyear_value != None: \n",
    "                authyear_value = authyear_value.replace(\"-\", \"\")\n",
    "                if len(authyear_value) == 4: \n",
    "                    try: \n",
    "                        authyear_value = int(authyear_value)\n",
    "                        epoche_value = get_epoch(authyear_value)\n",
    "                    except: \n",
    "                        epoche_value = None \n",
    "                elif len(authyear_value) == 8: \n",
    "                    try: \n",
    "                        authyear_value = int(authyear_value[:4])\n",
    "                        epoche_value = get_epoch(authyear_value)\n",
    "                    except: \n",
    "                        authyear_value = int(authyear_value[4:])\n",
    "                        epoche_value = get_epoch(authyear_value) \n",
    "                else: \n",
    "                    epoche_value = None\n",
    "            else: \n",
    "                epoche_value = None\n",
    "        except:\n",
    "            epoche_all = \"\"\n",
    "            for el in range(len(record.get_fields(authyear2_no))):\n",
    "                if get_record_value(record, authyear2_no, authyear2_sub)!= None:\n",
    "                    authyear2_val = get_record_value(record, authyear2_no, authyear2_sub)  \n",
    "                    authyear2_value = authyear2_val.replace(\"-\", \"\")\n",
    "                    if len(authyear2_value) == 4: \n",
    "                        try: \n",
    "                            authyear2_value = int(authyear2_value)\n",
    "                            epoche_value = get_epoch(authyear2_value)\n",
    "                        except: \n",
    "                            epoche_value = None \n",
    "                    elif len(authyear2_value) == 8: \n",
    "                        try: \n",
    "                            authyear2_value = int(authyear2_value[:4])\n",
    "                            epoche_value = get_epoch(authyear2_value)\n",
    "                        except: \n",
    "                            try: \n",
    "                                authyear2_value = int(authyear2_value[4:])\n",
    "                                epoche_value = get_epoch(authyear2_value) \n",
    "                            except: \n",
    "                                epoche_value = None \n",
    "                    else: \n",
    "                        epoche_value = None \n",
    "                    try: \n",
    "                        epoche_all += \";\" +  epoche_value \n",
    "                    except: \n",
    "                        continue\n",
    "\n",
    "        if epoche_all: \n",
    "            epoche_all = epoche_all[1:] \n",
    "            epoche_lst = epoche_all.split(\";\")\n",
    "            epoche_lst = [el.strip() for el in epoche_lst]\n",
    "            epoche_value = ';'.join(list(dict.fromkeys(epoche_lst)))\n",
    "            epoche_value = epoche_value.strip() \n",
    "\n",
    "\n",
    "        # nicht durchsuchbare Felder:      \n",
    "        # MMS-ID & Swisscovery-Link\n",
    "        if len(record.get_fields(mms_id_no)) != 0:\n",
    "            mms_id_value = record.get_fields(mms_id_no)[0].value()\n",
    "            slink_value = \"https://uzb.swisscovery.slsp.ch/permalink/41SLSP_UZB/1d8t6qj/alma\" + str(mms_id_value)\n",
    "        else: \n",
    "            mms_id_value = None\n",
    "            slink_value = None\n",
    "        \n",
    "        # ISBN\n",
    "        isbn_value = get_repeatable_field_value(record, isbn_no, isbn_sub)\n",
    "        \n",
    "        # Inhaltsverzeichnis-Link\n",
    "        ilink_value = get_repeatable_field_value(record, ilink_no, ilink_sub)\n",
    "        \n",
    "        \n",
    "        # Resultate: \n",
    "        results_dict[index] = (titel_value, vorname_value, nachname_value, autor2_values, editor_values, verlag_value, pubort_value, erschdat_value, auflage_value, beschr_value, lang_value, ctry_value, geo_value, genr_value, publart_value, thema_value, zus_value, epoche_value, mms_id_value, isbn_value, slink_value, ilink_value)\n",
    "        #print(index)\n",
    "        pbar.update(1)\n",
    "\n",
    "    if 'nextRecordPosition' in dict_data['searchRetrieveResponse'].keys(): \n",
    "        nextpage = dict_data['searchRetrieveResponse']['nextRecordPosition']\n",
    "        nextpage = int(nextpage) + timeout_page\n",
    "        #print(nextpage)\n",
    "    else: \n",
    "        break \n",
    "\n",
    "pbar.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warten Sie bis der Ladebalken vollständig geladen hat.** <br>\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Warnung:</b> Falls das Herunterladen wegen Verbindungsproblemen unterbrochen wurde, so kann man den Code unterhalb auskommentieren und im oberen Code-Block die Variable `timeout_page` mit dem Wert der Ausgabe des Code-Blocks unten ersetzen, bevor man den oberen Code-Block erneut ausführt. So kann man die Suche weiterführen ohne von vorn beginnen zu müssen.\n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(nextpage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='strukturierung_des_suchresultats'></a>\n",
    "## Strukturierung des Suchresultats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Suchergebnisse werden tabellarisch mit den Ausgabefeldern als Spaltenname dargestellt. Die Suchergebnisse enthalten dadurch detaillierte Informationen zu den einzelnen Werken. Dies erleichtert es, eine fundierte Entscheidung über die Medien zu treffen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Titel</th>\n",
       "      <th>Autor</th>\n",
       "      <th></th>\n",
       "      <th>Weitere Autoren</th>\n",
       "      <th>Editoren</th>\n",
       "      <th>Verlag</th>\n",
       "      <th>Publikationsort</th>\n",
       "      <th>Erscheinungsdatum</th>\n",
       "      <th>Auflage</th>\n",
       "      <th>Physische Beschreibung</th>\n",
       "      <th>...</th>\n",
       "      <th>Geographisches Thema</th>\n",
       "      <th>Form/Genre</th>\n",
       "      <th>Ressourcentyp</th>\n",
       "      <th>Thema</th>\n",
       "      <th>Zusammenfassung</th>\n",
       "      <th>Epoche</th>\n",
       "      <th>MMS-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Swisscovery-Link</th>\n",
       "      <th>Inhaltsverzeichnis-Link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Vorname</th>\n",
       "      <th>Nachname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>...</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'Polygonaceae', 34</td>\n",
       "      <td>John</td>\n",
       "      <td>Brandbyge</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Berlings</td>\n",
       "      <td>Arlöv</td>\n",
       "      <td>1989</td>\n",
       "      <td>None</td>\n",
       "      <td>Berlings</td>\n",
       "      <td>...</td>\n",
       "      <td>Berlings</td>\n",
       "      <td>None</td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td>Berlings</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>991054745059705501</td>\n",
       "      <td>Berlings</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aizoaceae, Cucurbitaceae, Eriocaulaceae ..</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>991071750299705501</td>\n",
       "      <td></td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7. Alpenländisches Expertenforum zum Thema Bes...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bundesanstalt für Alpenländische Landwirtschaft</td>\n",
       "      <td>Gumpenstein</td>\n",
       "      <td>2001</td>\n",
       "      <td>None</td>\n",
       "      <td>Bundesanstalt für Alpenländische Landwirtschaft</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Bundesanstalt für Alpenländische Landwirtschaft</td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td>Bundesanstalt für Alpenländische Landwirtschaft</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>991147798699705501</td>\n",
       "      <td>Bundesanstalt für Alpenländische Landwirtschaft</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abnehmen mit der Sirtfood-Diät :, Den Stoffwe...</td>\n",
       "      <td>Doris.</td>\n",
       "      <td>Muliar</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Riva</td>\n",
       "      <td>München :;München</td>\n",
       "      <td>2020</td>\n",
       "      <td>None</td>\n",
       "      <td>Riva,</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>Riva,</td>\n",
       "      <td>Buch - elektronisch</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>991170644874605501</td>\n",
       "      <td>Riva,</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Adhäsion von Porphyromonas gingivalis: Antiadh...</td>\n",
       "      <td>Gesine</td>\n",
       "      <td>Löhr</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Münster</td>\n",
       "      <td>2010</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>991081238699705501</td>\n",
       "      <td>None</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Das XXL Kochbuch Basische Ernährung! Inklusive...</td>\n",
       "      <td>Daike.</td>\n",
       "      <td>Rothbach</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tredition Verlag</td>\n",
       "      <td>Ahrensburg :;Ahrensburg</td>\n",
       "      <td>2023</td>\n",
       "      <td>None</td>\n",
       "      <td>tredition Verlag,</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Buch - elektronisch</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>991171152846005501</td>\n",
       "      <td>tredition Verlag,</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Die Züchtung von Kartoffel, Erdbirne, Lein, Ha...</td>\n",
       "      <td>Carl</td>\n",
       "      <td>Fruwirth</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Parey</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>1924</td>\n",
       "      <td>Parey</td>\n",
       "      <td>Parey</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Neuzeit</td>\n",
       "      <td>991146999089705501</td>\n",
       "      <td>None</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Zufällig vegan, 100 Rezepte für die regionale ...</td>\n",
       "      <td>Marta</td>\n",
       "      <td>Dymek</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>smarticular Verlag</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>2019</td>\n",
       "      <td>None</td>\n",
       "      <td>smarticular Verlag</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>smarticular Verlag</td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td>smarticular Verlag</td>\n",
       "      <td>None</td>\n",
       "      <td>Gegenwart</td>\n",
       "      <td>991132489089705501</td>\n",
       "      <td>smarticular Verlag</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>smarticular Verlag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Zugehörigkeiten und Esskultur, Alltagspraxen ...</td>\n",
       "      <td>Anna</td>\n",
       "      <td>Flack</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Bielefeld</td>\n",
       "      <td>2020</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Buch - elektronisch</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>991170585711605501</td>\n",
       "      <td></td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Zusammensetzung der Pseudogetreidearten Amaran...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Stuttgart</td>\n",
       "      <td>1997</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>Buch - physisch</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>991153222929705501</td>\n",
       "      <td>None</td>\n",
       "      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Titel   Autor             \\\n",
       "                                                       Vorname   Nachname   \n",
       "ID                                                                          \n",
       "1                                   'Polygonaceae', 34    John  Brandbyge   \n",
       "2           Aizoaceae, Cucurbitaceae, Eriocaulaceae ..                      \n",
       "3    7. Alpenländisches Expertenforum zum Thema Bes...                      \n",
       "4    Abnehmen mit der Sirtfood-Diät :, Den Stoffwe...  Doris.     Muliar   \n",
       "5    Adhäsion von Porphyromonas gingivalis: Antiadh...  Gesine       Löhr   \n",
       "..                                                 ...     ...        ...   \n",
       "192  Das XXL Kochbuch Basische Ernährung! Inklusive...  Daike.   Rothbach   \n",
       "193  Die Züchtung von Kartoffel, Erdbirne, Lein, Ha...    Carl   Fruwirth   \n",
       "194  Zufällig vegan, 100 Rezepte für die regionale ...   Marta      Dymek   \n",
       "195  Zugehörigkeiten und Esskultur, Alltagspraxen ...    Anna      Flack   \n",
       "196  Zusammensetzung der Pseudogetreidearten Amaran...                      \n",
       "\n",
       "    Weitere Autoren Editoren                                           Verlag  \\\n",
       "                                                                                \n",
       "ID                                                                              \n",
       "1              None     None                                         Berlings   \n",
       "2              None     None                                                    \n",
       "3              None     None  Bundesanstalt für Alpenländische Landwirtschaft   \n",
       "4              None     None                                             Riva   \n",
       "5              None     None                                                    \n",
       "..              ...      ...                                              ...   \n",
       "192            None     None                                 tredition Verlag   \n",
       "193            None     None                                            Parey   \n",
       "194            None     None                               smarticular Verlag   \n",
       "195            None     None                                             None   \n",
       "196                                                                             \n",
       "\n",
       "             Publikationsort Erscheinungsdatum Auflage  \\\n",
       "                                                         \n",
       "ID                                                       \n",
       "1                      Arlöv              1989    None   \n",
       "2                       None                      None   \n",
       "3                Gumpenstein              2001    None   \n",
       "4        München :;München              2020    None   \n",
       "5                    Münster              2010    None   \n",
       "..                       ...               ...     ...   \n",
       "192  Ahrensburg :;Ahrensburg              2023    None   \n",
       "193                   Berlin              1924   Parey   \n",
       "194                   Berlin              2019    None   \n",
       "195                Bielefeld              2020           \n",
       "196                Stuttgart              1997    None   \n",
       "\n",
       "                              Physische Beschreibung  ...  \\\n",
       "                                                      ...   \n",
       "ID                                                    ...   \n",
       "1                                           Berlings  ...   \n",
       "2                                                     ...   \n",
       "3    Bundesanstalt für Alpenländische Landwirtschaft  ...   \n",
       "4                                              Riva,  ...   \n",
       "5                                                     ...   \n",
       "..                                               ...  ...   \n",
       "192                                tredition Verlag,  ...   \n",
       "193                                            Parey  ...   \n",
       "194                               smarticular Verlag  ...   \n",
       "195                                                   ...   \n",
       "196                                                   ...   \n",
       "\n",
       "    Geographisches Thema                                       Form/Genre  \\\n",
       "                                                                            \n",
       "ID                                                                          \n",
       "1               Berlings                                             None   \n",
       "2                                                                    None   \n",
       "3                   None  Bundesanstalt für Alpenländische Landwirtschaft   \n",
       "4                   None                                            Riva,   \n",
       "5                   None                                                    \n",
       "..                   ...                                              ...   \n",
       "192                 None                                             None   \n",
       "193                 None                                             None   \n",
       "194                 None                               smarticular Verlag   \n",
       "195                 None                                             None   \n",
       "196                 None                                                    \n",
       "\n",
       "           Ressourcentyp                                            Thema  \\\n",
       "                                                                            \n",
       "ID                                                                          \n",
       "1        Buch - physisch                                         Berlings   \n",
       "2        Buch - physisch                                                    \n",
       "3        Buch - physisch  Bundesanstalt für Alpenländische Landwirtschaft   \n",
       "4    Buch - elektronisch                                             None   \n",
       "5        Buch - physisch                                                    \n",
       "..                   ...                                              ...   \n",
       "192  Buch - elektronisch                                             None   \n",
       "193      Buch - physisch                                             None   \n",
       "194      Buch - physisch                               smarticular Verlag   \n",
       "195  Buch - elektronisch                                                    \n",
       "196      Buch - physisch                                                    \n",
       "\n",
       "    Zusammenfassung     Epoche              MMS-ID  \\\n",
       "                                                     \n",
       "ID                                                   \n",
       "1              None             991054745059705501   \n",
       "2              None             991071750299705501   \n",
       "3              None             991147798699705501   \n",
       "4              None       None  991170644874605501   \n",
       "5              None       None  991081238699705501   \n",
       "..              ...        ...                 ...   \n",
       "192            None       None  991171152846005501   \n",
       "193            None    Neuzeit  991146999089705501   \n",
       "194            None  Gegenwart  991132489089705501   \n",
       "195                       None  991170585711605501   \n",
       "196            None             991153222929705501   \n",
       "\n",
       "                                                ISBN  \\\n",
       "                                                       \n",
       "ID                                                     \n",
       "1                                           Berlings   \n",
       "2                                                      \n",
       "3    Bundesanstalt für Alpenländische Landwirtschaft   \n",
       "4                                              Riva,   \n",
       "5                                               None   \n",
       "..                                               ...   \n",
       "192                                tredition Verlag,   \n",
       "193                                             None   \n",
       "194                               smarticular Verlag   \n",
       "195                                                    \n",
       "196                                             None   \n",
       "\n",
       "                                      Swisscovery-Link Inhaltsverzeichnis-Link  \n",
       "                                                                                \n",
       "ID                                                                              \n",
       "1    https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "2    https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "3    https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "4    https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "5    https://uzb.swisscovery.slsp.ch/permalink/41SL...                          \n",
       "..                                                 ...                     ...  \n",
       "192  https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "193  https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "194  https://uzb.swisscovery.slsp.ch/permalink/41SL...      smarticular Verlag  \n",
       "195  https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "196  https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n",
       "\n",
       "[196 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suchergebnis als Tabelle\n",
    "df = pd.DataFrame.from_dict(results_dict, orient='index')\n",
    "\n",
    "#Spaltennamen \n",
    "df.columns = [['Titel', 'Autor', '', 'Weitere Autoren', 'Editoren', 'Verlag', 'Publikationsort', 'Erscheinungsdatum', 'Auflage', 'Physische Beschreibung', 'Sprache', 'Land', 'Geographisches Thema', 'Form/Genre', 'Ressourcentyp', 'Thema', 'Zusammenfassung', 'Epoche', 'MMS-ID', 'ISBN', 'Swisscovery-Link', 'Inhaltsverzeichnis-Link'], \n",
    "              ['', 'Vorname', 'Nachname', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']]\n",
    "#Reihenindex\n",
    "df.index.name = 'ID'\n",
    "df.index += 1 \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exportieren_des_suchresultats'></a>\n",
    "## Exportieren des Suchresultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Suchresultat kann als Excel, CSV oder JSON exportiert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_excel(\"ZB_Suchresultat.xlsx\", sheet_name='Resultat')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"ZB_Suchresultat.csv\", index=False, sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_json('ZB_Suchresultat.json', orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jetzt kann die Ergebnisdatei im Verzeichnis dieses Jupyter Notebooks geöffnet werden.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tipp:</b> Sie können die Ergebnisse weiter filtern z.B. nach Sprache, Autor, Thema oder anderen Kriterien. Die Suchergebnisse können auch sortiert werden, z.B. alphabetisch nach Autor oder nach Erscheinungsjahr. Dies erhöht die Chance, dass die gewünschten Materialien gefunden werden. Klicken Sie auf den Swisscovery-Link, um weitere Details zu sehen wie Bibliotheksstandort, Signatur und Verfügbarkeit des Mediums.  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optionaler Zusatz: Download der Inhaltsverzeichnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Inhaltsverzeichnisse zu jedem Medium können dank dem Inhaltsverzeichnislink in der Tabelle auf den lokalen Computer als Datei heruntergeladen werden, falls so ein Link zum Medium existiert. \n",
    "\n",
    ">Kommentieren Sie den untenstehen Code-Block aus (Wegnehmen der zwei Mal drei Gänsefüsschen am Anfang und Ende) und geben Sie den Speicherort `save_to_path` der zu herunterladenden Inhaltsverzeichnisse an, bevor Sie ihn ausführen. Ansonsten werden die Inhaltsverzeichnisse als PDF-Dateien im aktuellen Verzeichnis (das des Jupyter Notebooks) abgespeichert.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nihv_dict = {}\\nfor i, row in df.iterrows(): \\n    if row[\\'Inhaltsverzeichnis-Link\\'][0] != None:\\n        titel_cap = []\\n        for el in row[\\'Titel\\', \\'\\'].split(\" \"): \\n            el = el[0].upper() + el[1:]\\n            titel_cap.append(el)\\n        titel_cap = \\' \\'.join(titel_cap)\\n        if len(row[\\'Inhaltsverzeichnis-Link\\'][0].split(\";\")) == 1: \\n            filename = f\"{i}_{row[\\'\\', \\'Nachname\\']}_{row[\\'Erscheinungsdatum\\', \\'\\']}_{titel_cap}\"\\n            remove_chars = \"[/:*?\"<>|],\\'- \"\\n            for char in remove_chars: \\n                filename = filename.replace(char, \"\")\\n            #filename = filename[:31]\\n            ihv_dict[filename] = row[\\'Inhaltsverzeichnis-Link\\'][0]\\n        else: \\n            for im, ihv_link in enumerate(list(row[\\'Inhaltsverzeichnis-Link\\'][0].split(\";\"))): \\n                filename = f\"{i}.{im+1}_{row[\\'\\', \\'Nachname\\']}_{row[\\'Erscheinungsdatum\\', \\'\\']}_{row[\\'Titel\\', \\'\\']}\"\\n                remove_chars = \"[/:*?\"<>|],\\'- \"\\n                for char in remove_chars: \\n                    filename = filename.replace(char, \"\")\\n                #filename = filename[:31]\\n                ihv_dict[filename] = ihv_link\\n\\nprint(\\'Es wurden \\', len(ihv_dict), \\' Links fürs Herunterladen gefunden.\\')\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ihv_dict = {}\n",
    "for i, row in df.iterrows(): \n",
    "    if row['Inhaltsverzeichnis-Link'][0] != None:\n",
    "        titel_cap = []\n",
    "        for el in row['Titel', ''].split(\" \"): \n",
    "            el = el[0].upper() + el[1:]\n",
    "            titel_cap.append(el)\n",
    "        titel_cap = ' '.join(titel_cap)\n",
    "        if len(row['Inhaltsverzeichnis-Link'][0].split(\";\")) == 1: \n",
    "            filename = f\"{i}_{row['', 'Nachname']}_{row['Erscheinungsdatum', '']}_{titel_cap}\"\n",
    "            remove_chars = \"[/:*?\\\"<>|],'- \"\n",
    "            for char in remove_chars: \n",
    "                filename = filename.replace(char, \"\")\n",
    "            #filename = filename[:31]\n",
    "            ihv_dict[filename] = row['Inhaltsverzeichnis-Link'][0]\n",
    "        else: \n",
    "            for im, ihv_link in enumerate(list(row['Inhaltsverzeichnis-Link'][0].split(\";\"))): \n",
    "                filename = f\"{i}.{im+1}_{row['', 'Nachname']}_{row['Erscheinungsdatum', '']}_{row['Titel', '']}\"\n",
    "                remove_chars = \"[/:*?\\\"<>|],'- \"\n",
    "                for char in remove_chars: \n",
    "                    filename = filename.replace(char, \"\")\n",
    "                #filename = filename[:31]\n",
    "                ihv_dict[filename] = ihv_link\n",
    "\n",
    "print('Es wurden ', len(ihv_dict), ' Links fürs Herunterladen gefunden.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsave_to_path = None\\n#save_to_path = r\"C:/Benutzer\"\\ni = 0\\nfor filename, link in ihv_dict.items(): \\n    try: \\n        response = requests.get(link)\\n        if not save_to_path: \\n            complete_path = os.path.expanduser(f\"~/downloads/{filename}.pdf\")\\n        else: \\n            complete_path = os.path.join(f\"{save_to_path}/{filename}.pdf\")\\n        with open(complete_path, \\'wb\\') as f: \\n            f.write(response.content)\\n        i += 1\\n    except: \\n        continue\\n\\nprint(\\'Es wurden \\', i, \\' von \\', len(ihv_dict), \\' Links heruntergeladen.\\')\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "save_to_path = None\n",
    "#save_to_path = r\"C:/Benutzer\"\n",
    "i = 0\n",
    "for filename, link in ihv_dict.items(): \n",
    "    try: \n",
    "        response = requests.get(link)\n",
    "        if not save_to_path: \n",
    "            complete_path = os.path.expanduser(f\"~/downloads/{filename}.pdf\")\n",
    "        else: \n",
    "            complete_path = os.path.join(f\"{save_to_path}/{filename}.pdf\")\n",
    "        with open(complete_path, 'wb') as f: \n",
    "            f.write(response.content)\n",
    "        i += 1\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "print('Es wurden ', i, ' von ', len(ihv_dict), ' Links heruntergeladen.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nachnutzung'></a>\n",
    "### Nachnutzung der Ergebnisse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Erstellung einer Bibliographie (= Liste von Referenzen)**\n",
    "\n",
    "Sie möchten alle Referenzdaten der Bücher mit einem bestimmten Suchbegriff (Autor, Titel, Verlag, Publikationsort, Erscheinungsdatum) herunterladen, z.B. für die Erstellung einer Bibliographie einer (akademischen) **Forschungsarbeit** oder zur Literaturauswertung zu Beginn einer Forschungsarbeit. Dazu braucht es Rohdaten, um diese einem gewissen Zitationsstil anpassen zu können. Auch Literaturverwaltungssysteme wie Citavi, Endnote, Mendeley und Zotero können mit den Daten eingepflegt werden.  \n",
    "- **Zugriff auf Swisscovery-Links für Bestellungen**\n",
    "\n",
    "In der Ergebnisdatei findet sich mitunter eine Spalte \"Swisscovery-Link\". Der Nutzer kann die [Swisscovery-Links](https://uzb.swisscovery.slsp.ch/discovery/search?vid=41SLSP_UZB:UZB) nutzen, um **Bücher vorbestellen bzw. reservieren** zu können. Dank den Swisscovery-Links können die Medien auf der Hauptseite der Bibliothek und weitere dazugehörige Informationen ausfindig gemacht werden; deren Standort (Bibliothek, Geschoss, Magazin), Signatur und Ausleihinformationen sind auf Swisscovery verfügbar. Die Swisscovery-Seite bietet auch noch weitere Filtermöglichkeiten an zur Einschränkung der Suche.  \n",
    "\n",
    "- **Überblick über alle Zusammenfassungen**\n",
    "\n",
    "In der Ergebnisdatei gibt es eine Spalte, die \"Zusammenfassung\" heisst. Der Nutzer kann die Zusammenfassungen/Abstracts eines Suchbegriffs dadurch einsehen. Eine Zusammenfassung bietet einen Überblick über das entsprechende Buch. Sie kann dazu dienen, zu verstehen, ob das Buch wirklich zum **Forschungsthema** passt, oder ob man es verwerfen kann.    \n",
    "- **Inhaltsverzeichnisse als PDF-Dateien**\n",
    "\n",
    "Die Ergebnisdatei beinhaltet die Spalte \"Inhaltsverzeichnis-Link\". Der Nutzer kann dank den Links alle Inhaltsverzeichnisse als PDF herunterladen, damit man bei mehreren Autoren eines Buches z.B. die **Autorenliste** im Inhaltsverzeichnis überblicken kann.  Mit der Spalte \"Inhaltsverzeichnis-Links\" können die Links zu den PDF-Inhaltsverzeichnissen mit ein paar Zeilen Code direkt lokal auf den Computer heruntergeladen werden. Die Dateinamen der PDF-Inhaltsverzeichnisse sind nach Index, Nachname des Autors, Erscheinungsjahr und abgekürzter Titel des Medium benannt.  \n",
    "\n",
    "- **Meta-Statistiken**\n",
    "\n",
    "Der Nutzer kann die detaillierten Angaben in der Ergebnisdatei als Suchresultat des Bibliothekskatalogs dazu nutzen, um damit  **statistische Analysen** der bibliographischen (Meta-)Daten durchzuführen. Z.B. kann nach Anzahl, Auflage, Sprache, Genre, Epoche und Thema analytisch erhoben werden. Man kann die Suchresultate mit geeigneten statistischen Diagrammen visuell anschaulich auswerten wie zum Beispiel Balken-, Kuchen oder Liniendiagramme.  \n",
    "\n",
    "- **Einbettung in Websites oder Web-Apps**\n",
    "\n",
    "Der Nutzer möchte das Suchresultat im JSON-Format in Websites oder Web-Apps einbetten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit den oben vorgeführten Schritten dieses Notebooks können Sie eine einfache Suchabfrage des SLSP-Bibliothekskatalogs durchführen, um den Bibliothekskatalog optimal zu nutzen und Medien zu finden, die Ihrem spezifischen Forschungsinteresse entsprechen. Dieses Jupyter Notebook bietet dazu eine optimierte und effiziente Möglichkeit, nach Medien zu suchen, welche die individuellen Anforderungen erfüllen. \n",
    "\n",
    "*Für weitere Fragen und Feedback wenden Sie sich bitte an Linda Samsinger, Metadaten-Expertin an der Zentralbibliothek Zürich, unter linda.samsinger@zb.uzh.ch.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zentralbibliothek Zürch** | Kantons-, Stadt- und Universitätsbibliothek \n",
    "\n",
    "Folgen Sie uns auf sozialen Medien:\n",
    "\n",
    "<nav>\n",
    "<a href=\"https://www.facebook.com/Zentralbibliothek.Zuerich/?locale=de_DE\">Facebook</a> |\n",
    "<a href=\"https://twitter.com/zbzuerich?lang=de\">Twitter</a> |\n",
    "<a href=\"https://www.youtube.com/channel/UCVLFfTBvY89xBI_rEBgmdvQ\">YouTube</a> |\n",
    "<a href=\"https://www.instagram.com/zentralbibliothek_zuerich/?hl=de\">Instagram</a> |\n",
    "<a href=\"https://ch.linkedin.com/company/zentralbibliothek-z%C3%BCrich\">LinkedIn</a>  \n",
    "</nav>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Inhaltsverzeichnis",
   "title_sidebar": "Inhaltsverzeichnis",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "373.875px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
