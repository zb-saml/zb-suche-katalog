{
  "metadata": {
    "anaconda-cloud": {},
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Inhaltsverzeichnis",
      "title_sidebar": "Inhaltsverzeichnis",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "373.875px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": false,
    "toc-showtags": false,
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Einfache Suche im SLSP-Bibliothekskatalog der *Zentralbibliothek Zürich*",
      "metadata": {
        "nbpresent": {
          "id": "d0d72cd5-034d-4b94-a4e2-54f7753cb9f0"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Zürich | 5. Mai 2023 - Linda Samsinger",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Die Zentralbibliothek Zürich ist eine der grössten Bibliotheken in der Schweiz und stellt eine breite Palette von Sammlungen, darunter Bücher, Zeitschriften, Audio- und Videomaterialien zur Verfügung. Die ZB Zürich hat Zugriff auf den **SLSP-Bibliothekskatalog, welcher Informationen zu allen in Schweizer Bibliotheken verfügbaren Medien enthält**.  \n\nDieses Jupyter Notebook beinhaltet Textanweisungen und Code-Blöcke zur fachkundigen **Abfrage des SLSP-Katalogs mit Suchbegriffen** und dem **Export des Suchresultats** als Excel, CSV oder JSON-Datei. Es erlaubt Ihnen, gezielt nach Medien zu suchen, welche Ihren spezifischen Interessen und Anforderungen entsprechen. \n\nDank diesem Tutorial können **bis zu 10'000 Suchresultate** heruntergeladen werden im Vergleich zur Suchabfrage auf der [Swisscovery-Webseite der UB und ZB Zürich](https://uzb.swisscovery.slsp.ch/discovery/search?vid=41SLSP_UZB:UZB), die es nur erlaubt maximal 50 Suchresultate zu exportieren. Zudem liegen die Suchresultate flach strukturiert und auf einer einzigen Seite übersichtlich vor. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Über dieses Jupyter Notebook werden nach **Eingabe von Suchbegriffen** im schweizweiten Netzwerk des SLSP-Bibliothekskatalogs  **alle bibliographischen Felder** nach entsprechenden Medien durchsucht. In der **Ausgabe enthalten sind die folgenden Felder**: Titel, Autor, Verlag, Publikationsort, Erscheinungsdatum, Auflage, physische Beschreibung, Sprache, Land, geographisches Thema, Form/Genre, Ressourcentyp, Thema, Zusammenfassung, Epoche, MMS-ID, ISBN, Swisscovery-Link und der Inhaltsverzeichnis-Link, falls vorhanden.   ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## Projektidee",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Mit diesem Notebook können Sie...",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "- **schweizweite Katalogdaten als Grundlage für die akademische Forschungsarbeit beziehen** \n- **Medien der Bibliotheken über Swisscovery-Links einfach bestellen und ausleihen**\n- **PDFs über die Inhaltsverzeichnis-Links in der Ergebnisdatei herunterladen**\n- **statistische Analysen von Katalogdaten durchführen.**\n\nFür eine weitere Auflistung von Vorteilen für den Benutzer siehe Sektion [Nachnutzung der Ergebnisse](#nachnutzung) weiter unten. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Ziel des Notebooks",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "![resultat](screenshot_suchresultat.png)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "![download](screenshot_download.png)",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Quelle: Der SLSP-Bibliothekskatalog ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Die Suchabfrage über den ganzen **SLSP-Bibliothekskatalog** von **über 25 Millionen Einträgen** schweizweit ist über die [Search/Retrieve-URL (SRU)-Schnittstelle (Version 1.2)](https://data.zb.uzh.ch/map/books/data-map-der-zentralbibliothek-zurich/page/alma-sru) der ZB Zürich verfügbar. Der SLSP-Bibliothekskatalog, der mithilfe dieses Jupyter Notebooks abgefragt wird, ist Teil des allgemein genutzten [Swisscovery-Katalogs](https://uzb.swisscovery.slsp.ch/discovery/search?vid=41SLSP_UZB:UZB), welcher allerdings über noch mehr Datenzuflüsse verfügt. \n- Datenquelle: https://data.zb.uzh.ch/map/books/data-map-der-zentralbibliothek-zurich/page/alma-sru\n- Datenformat: [MARCXML](https://www.loc.gov/standards/marcxml//)",
      "metadata": {
        "nbpresent": {
          "id": "ee78241c-36e7-45e6-b015-0ef46f1e777d"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "<a id='konfiguration_der_suchabfrage'></a>\n## Konfiguration der Suchabfrage",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Import der Programmabhängigkeiten",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Dieses Jupyter Notebook wurde mit Python 3.9.12 erstellt.  ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#!python --version",
      "metadata": {
        "trusted": true
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Im folgenden Code-Block werden die benutzten Programmmodule importiert. Bei Bedarf müssen die Programmmodule vorgängig in einer virtuellen Umgebung installiert werden bevor sie importierbar sind. Dazu kommentiert man den dazugehörigen Code ein: ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import piplite\nawait piplite.install('numpy')\nawait piplite.install('pandas')\nawait piplite.install('xmltodict')\nawait piplite.install('pymarc')\nawait piplite.install('ipywidgets')\nawait piplite.install('openpyxl')\nawait piplite.install('asyncio')",
      "metadata": {
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Module importieren \nimport asyncio\nimport urllib.parse\nfrom io import BytesIO\nimport micropip\nfrom pyodide.http import open_url, pyfetch\nfrom pathlib import Path\nimport requests, os\nfrom bs4 import BeautifulSoup as soup\nfrom lxml import etree\nimport pandas as pd\nimport xmltodict\nimport pymarc\nfrom IPython.display import display, HTML, Javascript \nfrom tqdm import tqdm\nimport functools as ft\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "Zusätzlich zu den Python-Modulen braucht es noch folgende Dateien im Jupyter Notebook-Verzeichnis: \n- `screenshot_suchresultat.png`\n- `screenshot_download.png`\n- `lang_dict.xlsx`\n- `country_dict.xlsx`",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Eingabe der Suchkriterien",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "> Führen Sie den nachstehenden Code-Block aus: \"Ctrl\" + \"Enter\" (oder Klick auf das Run-Stopp-Zeichen des Code-Blocks). ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import ipywidgets as widgets \nfrom ipywidgets import Layout\n\n# Widget \"Suchbox\" anzeigen \nform_item_layout = Layout(\n    display='flex',\n    flex_flow='row',\n    justify_content='space-around', \n    width='50%'\n    , grid_area='sidebar', align_items = 'center'\n)\n\ntext = widgets.Text(\n    placeholder='z.B. nach \"Geschichte alt* Ägypten\" im SLSP-Katalog',\n    description='Stichwort: ',\n    disabled=False\n    , layout=form_item_layout\n)\n\ndisplay(text)\n",
      "metadata": {
        "trusted": true
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Text(value='', description='Stichwort: ', layout=Layout(align_items='center', display='flex', flex_flow='row',…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "631d76f0973747348573d171aea44c0a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": "print(\"Ihr Suchbegriff:\\033[1m\", text.value, \"\\033[0m\")",
      "metadata": {
        "trusted": true
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "text": "Ihr Suchbegriff:\u001b[1m Gerstenmalz \u001b[0m\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "**Geben Sie Ihren Suchbegriff in die Suchbox ein.** Der Suchbegriff wird mit der \"Enter\"-Taste gespeichert.\n<div class=\"alert alert-block alert-info\">\n<b>Tipp:</b> Ein möglicher Suchbegriff für den SLSP-Bibliothekskatalog ist der Titel eines Buches, der für Ihre Forschung relevant sein könnte. Ein weiterer möglicher Suchbegriff wäre der Autor eines Buches oder der Artikel, den Sie benötigen. Andere mögliche Suchbegriffe sind Themenbegriffe oder Schlagworte, die mit Ihrem Forschungsinteresse zuammenhängen, oder Erscheinungsjahr und Sprache. Basierend auf dem Suchbegriff wird eine einfache Suchabfrage gestartet, die alle bibliografischen Felder durchsucht. </div>\n ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<a id='durchführung_der_suchabfrage'></a>\n## Durchführung der Suchabfrage",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "> **Klick auf \"Run All Below\"**: Ab dieser Konfigurationsstelle kann der ganze verbleibende Code in einem Zug durchgespielt werden. Klicken Sie dazu auf den darunter stehenden Code-Block, dann im Navigationsmenu auf \"Cell\" und dann auf \"Run All Below\", um alle Code-Blöcke auf einmal auszuführen. Die Ausführung kann je nach Anzahl der gefundenen Ergebnisse unterschiedlich lang dauern.  ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Laden von externen Listen und Funktionen",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Sprachen \ndf = pd.read_excel(r'lang_dict.xlsx')\nlang_dict = dict(zip(df.LangCode, df.LangDe))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def get_lang(lang_value): \n    sprach_value = ''\n    for key, value in lang_dict.items(): \n        if key == lang_value: \n            if value == 'None': \n                sprach_value = None \n            else: \n                sprach_value = value \n\n    return sprach_value ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Länder\ndf = pd.read_excel(r'country_dict.xlsx')\nctry_dict = dict(zip(df.CountryCode, df.CountryDe))",
      "metadata": {
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def get_country(country_code): \n    country_value = ''\n    for key, value in ctry_dict.items(): \n        if key == country_code:\n            if value == 'None': \n                country_value = None \n            else: \n                country_value = value \n\n    return country_value ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Epoche\ndef get_epoch(lebens_value):\n    if type(lebens_value) == int: \n        if lebens_value <500: \n            epoche_value = 'Antike'\n        elif lebens_value <1492: \n            epoche_value = 'Mittelalter'\n        elif lebens_value <1914: \n            epoche_value = 'Neuzeit'\n        else: \n            epoche_value = 'Gegenwart'\n    else: \n        epoche_value = None\n    return epoche_value     ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Ressourcentyp \npubart_dict = {'a': 'Sprachmaterial', \n            'c': 'Noten', \n            'd': 'Noten',\n            'e': 'Karte', \n            'f': 'Karte',\n            'g': 'Projektionsmedium', \n            'i': 'Tonaufnahme', \n            'j': 'Tonaufnahme',\n            'k': 'Grafik', \n            'm': 'Computerdatei',\n            'o': 'Satz', \n            'p': 'Gemischt', \n            'r': 'Artefakt',\n            't': 'Sprachmaterial'} \n\ndef get_pubart(pubart_value): \n    pbrt_value = ''\n    for key, value in pubart_dict.items(): \n        if key == str(pubart_value): \n            pbrt_value = value \n\n    return pbrt_value ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "pubart2_dict = {'a': 'Monographie', \n            'b': 'Zeitschrift', \n            'c': 'Sammlung',\n            'd': 'Untereinheit', \n            'i': 'Integrierende Ressource',\n            'm': 'Einzeldarstellung', \n            's': 'Zeitschrift'} \n\ndef get_pubart2(pubart2_value): \n    pbrt2_value = ''\n    for key, value in pubart2_dict.items(): \n        if key == str(pubart2_value): \n            pbrt2_value = value \n\n    return pbrt2_value ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def get_pubart3(pubart3_value): \n    pbrt3_value = ''\n    if pubart3_value == 'o' or pubart3_value == 'q' or pubart3_value == 's': \n        pbrt3_value = \"elektronisch\" \n    else: \n        pbrt3_value = \"physisch\"\n    return pbrt3_value   ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# wiederholbare Felder \ndef get_repeatable_field_value(record, field_no, field_sub, sep=\";\"): \n        repeatable_field_value = \"\"\n        if len(record.get_fields(field_no)) != 0:\n            for el in range(len(record.get_fields(field_no))):\n                try:\n                    if record.get_fields(field_no)[el][field_sub]!= None:\n                        repeatable_field_val = record.get_fields(field_no)[el][field_sub]            \n                        repeatable_field_value += sep + repeatable_field_val \n                except: \n                    continue\n        else: \n            repeatable_field_value = None \n        try: \n            repeatable_field_value = repeatable_field_value[1:]\n        except: \n            repeatable_field_value = None\n        return repeatable_field_value",
      "metadata": {
        "trusted": true
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Feldwerte\ndef get_record_value(record, field_no, field_sub): \n    record_value = \"\"\n    try: \n        record_value = record.get_fields(field_no)[0][field_sub]\n    except: \n        pass\n    return record_value ",
      "metadata": {
        "trusted": true
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Definition der Ausgabefelder",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# durchsuchbare Felder\ntitel_no = '245' #Titel-MARC\ntitel_sub = 'a' #Titel-MARC (Haupttitel)\ntitel_sub2 = 'b' #Titel-MARC (Untertitel)\nautor_no = '100' #Autor-MARC \nautor_sub = 'a' #Autor-MARC \nautor2_no = '700' #Weitere Autoren-MARC  \nautor2_sub1 = 'a' #Weitere Autoren-MARC  \nautor2_sub2 = '4' #Weitere Autoren-MARC \neditor_no = '700' #Editoren-MARC \neditor_sub1 = 'a' #Editoren-MARC\neditor_sub2 = '4' #Editoren-MARC\neditor_sub3 = 'e'  #Editoren-MARC\nverlag_no = '264' #Verlag-MARC\nverlag_sub = 'b' #Verlag-MARC\npubort_no = '260' #Publikationsort-MARC\npubort_sub = 'a' #Publikationsort-MARC\npubort_no2 = '264' #Publikationsort-MARC\npubort_sub2 = 'a' #Publikationsort-MARC\nerschdat_no = '260' #Erscheinungsdatum-MARC\nerschdat_sub = 'c' #Erscheinungsdatum-MARC\nerschdat_no2 = '264' #Erscheinungsdatum-MARC\nerschdat_sub2 = 'c' #Erscheinungsdatum-MARC\nerschdat_no3 = '008' #Erscheinungsdatum-MARC\nthema_no = '650' #Thema-MARC\nthema_sub = 'a' #Thema-MARC\nsprache_no = '008' #Sprache-MARC\nland_no = '008' #Land-MARC\ngeo_no = '651' #Geographisches-Thema-MARC\ngeo_sub = 'a' #Geographisches-Thema-MARC\nauflage_no = '250' #Auflage-MARC\nauflage_sub = 'a' #Auflage-MARC\nzus_no = '520' #Zusammenfassung-MARC\nzus_sub = 'a' #Zusammenfassung-MARC\ngenr_no = '655' #Form/Genre-MARC\ngenr_sub = 'a' #Form/Genre-MARC\nbeschr_no = '300' #Beschreibung-MARC\nbeschr_sub = 'a' #Beschreibung-MARC\npubart3_no = '008' #Ressourcentyp-MARC\nauthyear_no = '100' #Epoche-MARC\nauthyear_sub = 'd' #Epoche-MARC\nauthyear2_no = '700' #Epoche-MARC\nauthyear2_sub = 'd' #Epoche-MARC\n\n# nichtdurchsuchbare Felder \nmms_id_no = '001' #MMS-ID-MARC\nisbn_no = '020' #ISBN-MARC\nisbn_sub = 'a' #ISBN-MARC\nilink_no = '856' #Swisscovery-MARC\nilink_sub = 'u' #Swisscovery-MARC",
      "metadata": {
        "trusted": true
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "### Öffnen der Suchseite",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Suchbegriff evaluieren\nkeyword = text.value\nreplacements = str.maketrans({'ä': 'ae', 'ö': 'oe', 'ü':'ue', 'Ä':'Ae','Ö':'Oe', 'Ü': 'Ue', 'è': 'e', 'é':'e'})\nkeyword = keyword.translate(replacements)\n\n# URL-Suchabfrage starten \nbase_url = \"https://slsp-network.alma.exlibrisgroup.com/view/sru/41SLSP_NETWORK?version=1.2&operation=searchRetrieve&recordSchema=marcxml&query=all_for_ui%20all%20%22\" + keyword + \"%22&startRecord=0\"\nbase_url = base_url.replace(\" \", \"%20\")\n\nparams = {'recordSchema' : 'marcxml',\n      'operation': 'searchRetrieveResponse',\n      'version': '1.2'\n     }\nr = open_url(base_url + \"&\" +urllib.parse.urlencode(params))\n#requests.get(base_url, params=params)\n\n#Suchergebnis analysieren\nxml = soup(r.read(), \"lxml\")\nno_records = int(xml.find('numberofrecords').text)\n\nprint('Es wurden ', str(no_records), ' Ergebnisse gefunden. Hinweis: Je mehr Ergebnisse vorhanden sind, desto länger dauert das Herunterladen.')\n",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 27,
      "outputs": [
        {
          "name": "stderr",
          "text": "/lib/python3.11/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Es wurden  5  Ergebnisse gefunden. Hinweis: Je mehr Ergebnisse vorhanden sind, desto länger dauert das Herunterladen.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "### Ausführung der Suche",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Seitenindex\ntimeout_page = 0 # die Zahl ersetzen, falls das Herunterladen unterbrochen wurde, siehe #print(nextpage)\nif timeout_page > 0: \n    timeout_page += 1 \nnextpage = 0 + timeout_page\nresults_dict = {}\n\n# Ladebalken \npbar = tqdm(total = int(no_records))\n\nfilename = \"website.xml\"\np = Path(filename)\n# Iteration über alle Webseiten der URL mit den Suchergebnissen \nwhile nextpage < no_records:\n    next_url = base_url[:-1] + str(nextpage + timeout_page)\n    response = open_url(next_url)\n    response_content = response.read()\n    try: \n        os.unlink(filename)\n    except: \n        pass\n    p.write_text(response_content)\n    dict_data = xmltodict.parse(response_content)\n    records = pymarc.parse_xml_to_array(p.name, strict=True)\n\n    for i, record in enumerate(records):\n        try: \n            index = int(dict_data['searchRetrieveResponse']['records']['record']['recordPosition'])\n        except: \n            index = int(dict_data['searchRetrieveResponse']['records']['record'][i]['recordPosition'])\n            \n        # durchsuchbare Felder:    \n\n        # Titel \n        titel_value = \"\"\n        if len(record.get_fields(titel_no)) != 0: \n            titel_value = get_record_value(record, titel_no, titel_sub)  \n            titel_value2 = get_record_value(record, titel_no, titel_sub2)\n            if titel_value2: \n                titel_value = ', '.join(filter(None, [titel_value, titel_value2]))\n        else: \n            titel_value = None \n        if titel_value != None and len(titel_value) > 1:\n            titel_value = titel_value.replace(\"[\", \"\")\n            titel_value = titel_value.replace(\"]\", \"\")\n            titel_value = titel_value.replace(\"<<\", \"\")\n            titel_value = titel_value.replace(\">>\", \"\")\n            if titel_value[-1] == \"/\" or titel_value[-1] == \".\": \n                titel_value = titel_value[:-1]\n        \n        # Autor\n        autor_value = \"\"\n        vorname_value = \"\"\n        nachname_value = \"\"\n        if len(record.get_fields(autor_no)) != 0: \n            autor_value = get_record_value(record, autor_no, autor_sub)              \n        else: \n            autor_value = None\n        if autor_value != None and len(autor_value) > 1:  \n            if autor_value[-1] == \",\" or (autor_value[-1] == \".\" and not type(autor_value[-2]) == str): \n                autor_value = autor_value[:-1]\n            autor_value = autor_value.strip()    \n            autor_lst = autor_value.split(',')\n            try: \n                vorname_value, nachname_value = autor_lst[1].strip(), autor_lst[0].strip()\n            except: \n                nachname_value = autor_lst[0]\n                vorname_value = None\n        \n        # Weitere Autoren\n        autor2_values = \"\"\n        autor2_lst2 = []\n        if len(record.get_fields(autor2_no)) != 0: \n            for el in range(len(record.get_fields(autor2_no))):\n                if get_record_value(record, autor2_no, autor2_sub2)  == 'aut': \n                    autor2_value = record.get_fields(autor2_no)[el][autor2_sub1]   \n                    autor2_values += \"; \" +  autor2_value \n        else: \n            autor2_values = None\n        if autor2_values!= None and len(autor2_values) > 1: \n            if autor2_values[0] == \";\": \n                autor2_values = autor2_values[1:].strip()\n            autor2_lst = [ el.split(\",\") for el in [el.strip()  for el in autor2_values.split(';') if el != '']] \n            for el in autor2_lst:\n                try: \n                    el[0], el[1] = el[1], el[0]\n                    autor2_names = el[0].strip() + ' ' + el[1].strip()\n                    autor2_lst2.append(autor2_names)\n                except: \n                    autor2_lst2.append(el[0])\n            autor2_values =  '; '.join(autor2_lst2) \n\n        \n        # Editoren\n        editor_values = \"\"\n        editor_lst2 = []\n        if len(record.get_fields(editor_no)) != 0: \n            for el in range(len(record.get_fields(editor_no))):\n                if get_record_value(record, editor_no, editor_sub2)  == 'edt': \n                    editor_value = record.get_fields(editor_no)[el][editor_sub1]   \n                    editor_values += \"; \" +  editor_value \n                try: \n                    if 'editor' in get_record_value(record, editor_no, editor_sub3): \n                        editor_value = record.get_fields(editor_no)[el][editor_sub1]   \n                        editor_values += \"; \" +  editor_value \n                except: \n                    continue\n        else: \n            editor_values = None\n        if editor_values!= None and len(editor_values) > 1: \n            if editor_values[0] == \";\": \n                editor_values = editor_values[1:].strip()\n            editor_lst = [el.split(\",\") for el in [el.strip() for el in editor_values.split(';') if el != '']]\n            for el in editor_lst: \n                try: \n                    el[0], el[1] = el[1], el[0]\n                    editor_lst = el[0].strip() + ' ' + el[1].strip()\n                    editor_lst2.append(editor_lst)\n                except: \n                    editor_lst2.append(el[0])\n                editor_values =  '; '.join(editor_lst2)\n    \n        # Verlag\n        verlag_value = get_repeatable_field_value(record, verlag_no, verlag_sub)\n        if verlag_value != None and len(verlag_value) > 1:\n            if verlag_value[-1] == \",\" or verlag_value[-1] == \":\": \n                verlag_value = verlag_value[:-1]\n            verlag_value = verlag_value.replace(\"[\", \"\")\n            verlag_value = verlag_value.replace(\"]\", \"\")\n            verlag_value = verlag_value.replace(\"?\", \"\")\n            verlag_value = verlag_value.strip() \n            \n        # Publikationsort\n        pubort_value = \"\"\n        if len(record.get_fields(pubort_no)) != 0:\n            for el in range(len(record.get_fields(pubort_no))):\n                try: \n                    if record.get_fields(pubort_no)[el][pubort_sub]!= None:\n                        pubort_val = record.get_fields(pubort_no)[el][pubort_sub]            \n                        pubort_value += \";\" + pubort_val   \n                except: \n                    continue\n        else: \n            pubort_value = \"\"\n            if len(record.get_fields(pubort_no2)) != 0:\n                for el in range(len(record.get_fields(pubort_no2))):\n                    if get_record_value(record, pubort_no2, pubort_sub2)!= None:\n                        pubort_val = get_record_value(record, pubort_no2, pubort_sub2)           \n                        pubort_value += \";\" + pubort_val     \n            else: \n                pubort_value = None \n            try: \n                pubort_value = pubort_value[1:]\n            except: \n                pubort_value = None \n        if pubort_value != None and len(pubort_value) > 1:\n            if pubort_value[0] == \";\" or pubort_value[0] == \",\" : \n                pubort_value = pubort_value[1:]\n            if pubort_value[-1] == \":\" or pubort_value[-1] == \";\": \n                pubort_value = pubort_value[:-1]\n            if type(pubort_value) == int: \n                pubort_value = None \n            pubort_value = pubort_value.replace(\"[\", \"\")\n            pubort_value = pubort_value.replace(\"]\", \"\")\n            pubort_value = pubort_value.replace(\"?\", \"\")\n            pubort_value = pubort_value.strip()\n            if pubort_value.isdigit():\n                pubort_value = None\n      \n         # Erscheinungsjahr\n        erschdat_value = \"\"\n        if len(record.get_fields(erschdat_no)) != 0:\n            for el in range(len(record.get_fields(erschdat_no))):\n                try: \n                    if record.get_fields(erschdat_no)[el][erschdat_sub]!= None:\n                        erschdat_val = record.get_fields(erschdat_no)[el][erschdat_sub]            \n                        erschdat_value += \";\" + erschdat_val \n                except: \n                    continue\n        else: \n            erschdat_value = \"\"\n            if len(record.get_fields(erschdat_no2)) != 0:\n                for el in range(len(record.get_fields(erschdat_no2))):\n                    if get_record_value(record, erschdat_no2, erschdat_sub2)!= None:\n                        erschdat_val = get_record_value(record, erschdat_no2, erschdat_sub2)            \n                        try: \n                            if erschdat_val[-1] == \".\": \n                                erschdat_val = erschdat_val[:-1]\n                            erschdat_value += \";\" + erschdat_val \n                        except: \n                            continue\n            else: \n                if len(record.get_fields(erschdat_no3)) != 0:\n                    erschdat_value = record.get_fields(erschdat_no3)[0].value()[6:11]            \n                else: \n                    erschdat_value = None \n        if erschdat_value != None and len(erschdat_value) > 1:  \n            if erschdat_value[0] == \";\": \n                erschdat_value = erschdat_value[1:]\n            if erschdat_value[-1] == \".\": \n                erschdat_value = erschdat_value[:-1]\n            erschdat_value = erschdat_value.replace(\"[\", \"\")\n            erschdat_value = erschdat_value.replace(\"]\", \"\")\n            erschdat_value = erschdat_value.replace(\"©\", \"\")\n            erschdat_value = erschdat_value.replace(\"℗\", \"\")\n            erschdat_value = erschdat_value.replace(\"?\", \"\")\n            erschdat_lst = erschdat_value.split(\";\")\n            erschdat_lst = [el.strip() for el in erschdat_lst] \n            for i, el in enumerate(erschdat_lst):  \n                try: \n                    if el[1].isdigit() and el[0].isalpha(): \n                        el = el.replace(el[0], \"\")\n                        erschdat_lst[i] = el\n                except: \n                    continue\n            erschdat_value = ';'.join(list(set(erschdat_lst)))\n            erschdat_value = erschdat_value.strip()\n        try: \n            if 'X' in erschdat_value or 'I' in erschdat_value or 'M' in erschdat_value or 'L' in erschdat_value or 'V' in erschdat_value: \n                erschdat_value = erschdat_value\n            else: \n                if 'J' not in erschdat_value: \n                    erschdat_lst = erschdat_value.split(\" \")\n                    erschdat_lst = [el for el in erschdat_lst if el.isdigit() or el[0].isdigit() or el[1].isdigit() or el[2].isdigit()]\n                    erschdat_value = ';'.join(list(dict.fromkeys(erschdat_lst)))\n                else: \n                    erschdat_value = erschdat_value\n        except: \n            pass   \n            \n        # Auflage   \n        auflage_value = get_repeatable_field_value(record, auflage_no, auflage_sub)\n        if auflage_value != None and len(auflage_value) > 1: \n            auflage_value = auflage_value.replace(\"[\", \"\")\n            auflage_value = auflage_value.replace(\"]\", \"\")\n        \n        # Physische Beschreibung\n        beschr_value = get_repeatable_field_value(record, beschr_no, beschr_sub)\n            \n        # Sprache\n        if len(record.get_fields(sprache_no)) != 0:\n            lang_value = record.get_fields(sprache_no)[0].value()[35:38] \n            if get_lang(lang_value) or get_lang(lang_value) == None: \n                lang_value = get_lang(lang_value)\n        else: \n            lang_value = None \n            \n        # Land\n        if len(record.get_fields(land_no)) != 0:\n            ctry_value = record.get_fields(land_no)[0].value()[15:18]\n            ctry_value = ctry_value.strip()\n            if get_country(ctry_value) or get_country(ctry_value) == None: \n                ctry_value = get_country(ctry_value)\n        else: \n            ctry_value = None \n        \n        # Geographisches Thema\n        geo_value = get_repeatable_field_value(record, geo_no, geo_sub)      \n        if geo_value != None and len(geo_value) > 1: \n            geo_value = geo_value.replace(\"[\", \"\")\n            geo_value = geo_value.replace(\"]\", \"\")\n            if geo_value[-1] == \".\" or geo_value[-1] == \";\": \n                geo_value = geo_value[:-1]\n            geo_value = geo_value.strip()\n            \n        # Form/Genre\n        genr_value = get_repeatable_field_value(record, genr_no, genr_sub)\n        if genr_value != None and len(genr_value) > 1:  \n            if genr_value[0] == \";\": \n                genr_value = genr_value[1:]\n            if genr_value[-1] == \".\": \n                genr_value = genr_value[:-1]\n            genr_value = genr_value.replace(\"[\", \"\")\n            genr_value = genr_value.replace(\"]\", \"\")\n            genr_lst = genr_value.split(\";\")\n            genr_lst = [el.strip() for el in genr_lst]\n            genr_value = ';'.join(list(set(genr_lst)))\n            genr_value = genr_value.strip()     \n        \n        #Ressourcentyp \n        if len(record.leader) != 0:\n            pubart_value = record.leader[6] \n            if get_pubart(pubart_value) or get_pubart(pubart_value) == None: \n                pubart_value = get_pubart(pubart_value)\n        else: \n            pubart_value = None \n     \n        if len(record.leader) != 0:\n            pubart2_value = record.leader[7] \n            if get_pubart2(pubart2_value) or get_pubart2(pubart2_value) == None: \n                pubart2_value = get_pubart2(pubart2_value)\n        else: \n            pubart2_value = None \n   \n        if len(record.get_fields(pubart3_no)) != 0:\n            try: \n                pubart3_value = record.get_fields(pubart3_no)[0].value()[23]\n            except: \n                pubart3_value = record.get_fields(pubart3_no)[0].value()[29]\n            if get_pubart3(pubart3_value) or get_pubart3(pubart3_value) == None: \n                pubart3_value = get_pubart3(pubart3_value)\n        else: \n            pubart3_value = None \n              \n        if pubart_value == 'Sprachmaterial' and (pubart2_value == 'Einzeldarstellung' or pubart2_value == 'Untereinheit' or pubart2_value == 'Sammlung' or pubart2_value == 'Monographie'): \n            publart_value = 'Buch' + ' - ' + pubart3_value\n        elif pubart_value == 'Sprachmaterial' and (pubart2_value == 'Integrierende Ressource' or pubart2_value == 'Zeitschrift'): \n            publart_value = 'Zeitschrift'  + ' - ' + pubart3_value\n        elif (pubart_value == 'Gemischt' or pubart_value == 'Satz' or pubart_value == 'Artefakt'): \n            publart_value = 'Gemischtes Material' + ' - ' + pubart3_value\n        elif pubart_value != 'Sprachmaterial' or pubart_value != 'Gemischt' or pubart_value != 'Satz' or pubart_value != 'Artefakt':    \n            publart_value = pubart_value + ' - ' + pubart3_value\n        else: \n            publart_value = None\n\n            \n        # Thema  \n        thema_value = get_repeatable_field_value(record, thema_no, thema_sub, sep=\" \") \n        if thema_value != None and len(thema_value) > 1: \n            thema_lst = thema_value.split(\" \")\n            thema_lst = [el.strip() for el in thema_lst if el != '']\n            thema_value = ' '.join(list(dict.fromkeys(thema_lst)))\n            thema_value = thema_value.strip()\n        \n        # Zusammenfassung\n        zus_value = get_repeatable_field_value(record, zus_no, zus_sub, sep=\" \") \n         \n        \n        # Epoche\n        epoche_value = \"\"\n        epoche_all = \"\"\n        try:\n            authyear_value = record.get_fields(authyear_no)[0][authyear_sub] \n            if authyear_value != None: \n                authyear_value = authyear_value.replace(\"-\", \"\")\n                if len(authyear_value) == 4: \n                    try: \n                        authyear_value = int(authyear_value)\n                        epoche_value = get_epoch(authyear_value)\n                    except: \n                        epoche_value = None \n                elif len(authyear_value) == 8: \n                    try: \n                        authyear_value = int(authyear_value[:4])\n                        epoche_value = get_epoch(authyear_value)\n                    except: \n                        authyear_value = int(authyear_value[4:])\n                        epoche_value = get_epoch(authyear_value) \n                else: \n                    epoche_value = None\n            else: \n                epoche_value = None\n        except:\n            epoche_all = \"\"\n            for el in range(len(record.get_fields(authyear2_no))):\n                if get_record_value(record, authyear2_no, authyear2_sub)!= None:\n                    authyear2_val = get_record_value(record, authyear2_no, authyear2_sub)  \n                    authyear2_value = authyear2_val.replace(\"-\", \"\")\n                    if len(authyear2_value) == 4: \n                        try: \n                            authyear2_value = int(authyear2_value)\n                            epoche_value = get_epoch(authyear2_value)\n                        except: \n                            epoche_value = None \n                    elif len(authyear2_value) == 8: \n                        try: \n                            authyear2_value = int(authyear2_value[:4])\n                            epoche_value = get_epoch(authyear2_value)\n                        except: \n                            try: \n                                authyear2_value = int(authyear2_value[4:])\n                                epoche_value = get_epoch(authyear2_value) \n                            except: \n                                epoche_value = None \n                    else: \n                        epoche_value = None \n                    try: \n                        epoche_all += \";\" +  epoche_value \n                    except: \n                        continue\n\n        if epoche_all: \n            epoche_all = epoche_all[1:] \n            epoche_lst = epoche_all.split(\";\")\n            epoche_lst = [el.strip() for el in epoche_lst]\n            epoche_value = ';'.join(list(dict.fromkeys(epoche_lst)))\n            epoche_value = epoche_value.strip() \n\n\n        # nicht durchsuchbare Felder:      \n        # MMS-ID & Swisscovery-Link\n        if len(record.get_fields(mms_id_no)) != 0:\n            mms_id_value = record.get_fields(mms_id_no)[0].value()\n            slink_value = \"https://uzb.swisscovery.slsp.ch/permalink/41SLSP_UZB/1d8t6qj/alma\" + str(mms_id_value)\n        else: \n            mms_id_value = None\n            slink_value = None\n        \n        # ISBN\n        isbn_value = get_repeatable_field_value(record, isbn_no, isbn_sub)\n        \n        # Inhaltsverzeichnis-Link\n        ilink_value = get_repeatable_field_value(record, ilink_no, ilink_sub)\n        \n        \n        # Resultate: \n        results_dict[index] = (titel_value, vorname_value, nachname_value, autor2_values, editor_values, verlag_value, pubort_value, erschdat_value, auflage_value, beschr_value, lang_value, ctry_value, geo_value, genr_value, publart_value, thema_value, zus_value, epoche_value, mms_id_value, isbn_value, slink_value, ilink_value)\n        #print(index)\n        pbar.update(1)\n\n    if 'nextRecordPosition' in dict_data['searchRetrieveResponse'].keys(): \n        nextpage = dict_data['searchRetrieveResponse']['nextRecordPosition']\n        nextpage = int(nextpage) + timeout_page\n        #print(nextpage)\n    else: \n        break \n\npbar.close()    ",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "name": "stderr",
          "text": "\n  0%|          | 0/5 [00:35<?, ?it/s]\u001b[A\n\n100%|██████████| 5/5 [00:00<00:00, 34.25it/s]\u001b[A\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "**Warten Sie bis der Ladebalken vollständig geladen hat.** <br>\n<div class=\"alert alert-block alert-danger\">\n<b>Warnung:</b> Falls das Herunterladen wegen Verbindungsproblemen unterbrochen wurde, so kann man den Code unterhalb auskommentieren und im oberen Code-Block die Variable `timeout_page` mit dem Wert der Ausgabe des Code-Blocks unten ersetzen, bevor man den oberen Code-Block erneut ausführt. So kann man die Suche weiterführen ohne von vorn beginnen zu müssen.\n</div> ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#print(nextpage)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a id='strukturierung_des_suchresultats'></a>\n## Strukturierung des Suchresultats\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Die Suchergebnisse werden tabellarisch mit den Ausgabefeldern als Spaltenname dargestellt. Die Suchergebnisse enthalten dadurch detaillierte Informationen zu den einzelnen Werken. Dies erleichtert es, eine fundierte Entscheidung über die Medien zu treffen. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Suchergebnis als Tabelle\ndf = pd.DataFrame.from_dict(results_dict, orient='index')\n\n#Spaltennamen \ndf.columns = [['Titel', 'Autor', '', 'Weitere Autoren', 'Editoren', 'Verlag', 'Publikationsort', 'Erscheinungsdatum', 'Auflage', 'Physische Beschreibung', 'Sprache', 'Land', 'Geographisches Thema', 'Form/Genre', 'Ressourcentyp', 'Thema', 'Zusammenfassung', 'Epoche', 'MMS-ID', 'ISBN', 'Swisscovery-Link', 'Inhaltsverzeichnis-Link'], \n              ['', 'Vorname', 'Nachname', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']]\n#Reihenindex\ndf.index.name = 'ID'\ndf.index += 1 \ndf",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 30,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                Titel     Autor             \\\n                                                        Vorname   Nachname   \nID                                                                           \n1   6.000 Jahre altes Gerstenmalz aus Hornstaad, B...    Renate  Ebersbach   \n2                                    Die Bierbrauerei    Ludwig    Narziss   \n3   Proanthocyanidine in den Braurohstoffen Gerste...  Wolfgang  Friedrich   \n4   Ueber den Eiweissabbau bei der Autolyse von Ge...    Rudolf       Buse   \n5   Über drei eigenartige Erstickungstodesfälle du...     Anton    Hufnagl   \n\n                     Weitere Autoren Editoren    Verlag Publikationsort  \\\n                                                                          \nID                                                                        \n1   Elena Marinova; Andreas G. Heiss               None            None   \n2                                                  None        Weinheim   \n3                               None     None                      Bonn   \n4                               None     None  Postberg    Bottrop i.W.   \n5                               None     None      Mayr        Würzburg   \n\n   Erscheinungsdatum                              Auflage  \\\n                                                            \nID                                                          \n1               2020                                 None   \n2               2009  8., überarbeitete und erg. Aufl. /   \n3               2000                                 None   \n4               1933                                 None   \n5               1939                                 None   \n\n        Physische Beschreibung  ... Geographisches Thema        Form/Genre  \\\n                                ...                                          \nID                              ...                                          \n1                         None  ...                 None              None   \n2   1 online resource (822 p.)  ...                 None              None   \n3                       183 S.  ...                 None  Hochschulschrift   \n4                        54 S.  ...                 None  Hochschulschrift   \n5                        30 S.  ...                 None  Hochschulschrift   \n\n          Ressourcentyp                                              Thema  \\\n                                                                             \nID                                                                           \n1       Buch - physisch                                               None   \n2   Buch - elektronisch                                     Beer. Brewing.   \n3       Buch - physisch  Braugerste HPLC-MS Malzextrakt Proanthocyanidi...   \n4       Buch - physisch                                               None   \n5       Buch - physisch                                               None   \n\n                                      Zusammenfassung     Epoche  \\\n                                                                   \nID                                                                 \n1             Bodensee - Malz - Bierherstellung - AOV  Gegenwart   \n2   Die lang erwartete, vollständig überarbeitet...  Gegenwart   \n3                                                None              \n4                                                None              \n5                                                None              \n\n                MMS-ID                                               ISBN  \\\n                                                                            \nID                                                                          \n1   991170872816905501                                               None   \n2   991170318083805501  1-282-31445-9;9786612314452;3-527-62863-0;3-52...   \n3   991116664539705501                                               None   \n4   991106171499705501                                               None   \n5   991021502469705501                                               None   \n\n                                     Swisscovery-Link Inhaltsverzeichnis-Link  \n                                                                               \nID                                                                             \n1   https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n2   https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n3   https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n4   https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n5   https://uzb.swisscovery.slsp.ch/permalink/41SL...                    None  \n\n[5 rows x 22 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>Titel</th>\n      <th>Autor</th>\n      <th></th>\n      <th>Weitere Autoren</th>\n      <th>Editoren</th>\n      <th>Verlag</th>\n      <th>Publikationsort</th>\n      <th>Erscheinungsdatum</th>\n      <th>Auflage</th>\n      <th>Physische Beschreibung</th>\n      <th>...</th>\n      <th>Geographisches Thema</th>\n      <th>Form/Genre</th>\n      <th>Ressourcentyp</th>\n      <th>Thema</th>\n      <th>Zusammenfassung</th>\n      <th>Epoche</th>\n      <th>MMS-ID</th>\n      <th>ISBN</th>\n      <th>Swisscovery-Link</th>\n      <th>Inhaltsverzeichnis-Link</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>Vorname</th>\n      <th>Nachname</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>...</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>6.000 Jahre altes Gerstenmalz aus Hornstaad, B...</td>\n      <td>Renate</td>\n      <td>Ebersbach</td>\n      <td>Elena Marinova; Andreas G. Heiss</td>\n      <td></td>\n      <td>None</td>\n      <td>None</td>\n      <td>2020</td>\n      <td>None</td>\n      <td>None</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Buch - physisch</td>\n      <td>None</td>\n      <td>Bodensee - Malz - Bierherstellung - AOV</td>\n      <td>Gegenwart</td>\n      <td>991170872816905501</td>\n      <td>None</td>\n      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Die Bierbrauerei</td>\n      <td>Ludwig</td>\n      <td>Narziss</td>\n      <td></td>\n      <td></td>\n      <td>None</td>\n      <td>Weinheim</td>\n      <td>2009</td>\n      <td>8., überarbeitete und erg. Aufl. /</td>\n      <td>1 online resource (822 p.)</td>\n      <td>...</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Buch - elektronisch</td>\n      <td>Beer. Brewing.</td>\n      <td>Die lang erwartete, vollständig überarbeitet...</td>\n      <td>Gegenwart</td>\n      <td>991170318083805501</td>\n      <td>1-282-31445-9;9786612314452;3-527-62863-0;3-52...</td>\n      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Proanthocyanidine in den Braurohstoffen Gerste...</td>\n      <td>Wolfgang</td>\n      <td>Friedrich</td>\n      <td>None</td>\n      <td>None</td>\n      <td></td>\n      <td>Bonn</td>\n      <td>2000</td>\n      <td>None</td>\n      <td>183 S.</td>\n      <td>...</td>\n      <td>None</td>\n      <td>Hochschulschrift</td>\n      <td>Buch - physisch</td>\n      <td>Braugerste HPLC-MS Malzextrakt Proanthocyanidi...</td>\n      <td>None</td>\n      <td></td>\n      <td>991116664539705501</td>\n      <td>None</td>\n      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ueber den Eiweissabbau bei der Autolyse von Ge...</td>\n      <td>Rudolf</td>\n      <td>Buse</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Postberg</td>\n      <td>Bottrop i.W.</td>\n      <td>1933</td>\n      <td>None</td>\n      <td>54 S.</td>\n      <td>...</td>\n      <td>None</td>\n      <td>Hochschulschrift</td>\n      <td>Buch - physisch</td>\n      <td>None</td>\n      <td>None</td>\n      <td></td>\n      <td>991106171499705501</td>\n      <td>None</td>\n      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Über drei eigenartige Erstickungstodesfälle du...</td>\n      <td>Anton</td>\n      <td>Hufnagl</td>\n      <td>None</td>\n      <td>None</td>\n      <td>Mayr</td>\n      <td>Würzburg</td>\n      <td>1939</td>\n      <td>None</td>\n      <td>30 S.</td>\n      <td>...</td>\n      <td>None</td>\n      <td>Hochschulschrift</td>\n      <td>Buch - physisch</td>\n      <td>None</td>\n      <td>None</td>\n      <td></td>\n      <td>991021502469705501</td>\n      <td>None</td>\n      <td>https://uzb.swisscovery.slsp.ch/permalink/41SL...</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 22 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": "<a id='exportieren_des_suchresultats'></a>\n## Exportieren des Suchresultats",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Das Suchresultat kann als Excel, CSV oder JSON exportiert werden. ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.to_excel(\"ZB_Suchresultat.xlsx\", sheet_name='Resultat')  ",
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#df.to_csv(\"ZB_Suchresultat.csv\", index=False, sep=';')",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "#df.to_json('ZB_Suchresultat.json', orient=\"index\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "**Jetzt kann die Ergebnisdatei im Verzeichnis dieses Jupyter Notebooks geöffnet werden.**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "<div class=\"alert alert-block alert-info\">\n<b>Tipp:</b> Sie können die Ergebnisse weiter filtern z.B. nach Sprache, Autor, Thema oder anderen Kriterien. Die Suchergebnisse können auch sortiert werden, z.B. alphabetisch nach Autor oder nach Erscheinungsjahr. Dies erhöht die Chance, dass die gewünschten Materialien gefunden werden. Klicken Sie auf den Swisscovery-Link, um weitere Details zu sehen wie Bibliotheksstandort, Signatur und Verfügbarkeit des Mediums.  </div>",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Optionaler Zusatz: Download der Inhaltsverzeichnisse",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Die Inhaltsverzeichnisse zu jedem Medium können dank dem Inhaltsverzeichnislink in der Tabelle auf den lokalen Computer als Datei heruntergeladen werden, falls so ein Link zum Medium existiert. \n\n>Kommentieren Sie den untenstehen Code-Block aus (Wegnehmen der zwei Mal drei Gänsefüsschen am Anfang und Ende) und geben Sie den Speicherort `save_to_path` der zu herunterladenden Inhaltsverzeichnisse an, bevor Sie ihn ausführen. Ansonsten werden die Inhaltsverzeichnisse als PDF-Dateien im aktuellen Verzeichnis (das des Jupyter Notebooks) abgespeichert.  ",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "'''\nihv_dict = {}\nfor i, row in df.iterrows(): \n    if row['Inhaltsverzeichnis-Link'][0] != None:\n        titel_cap = []\n        for el in row['Titel', ''].split(\" \"): \n            el = el[0].upper() + el[1:]\n            titel_cap.append(el)\n        titel_cap = ' '.join(titel_cap)\n        if len(row['Inhaltsverzeichnis-Link'][0].split(\";\")) == 1: \n            filename = f\"{i}_{row['', 'Nachname']}_{row['Erscheinungsdatum', '']}_{titel_cap}\"\n            remove_chars = \"[/:*?\\\"<>|],'- \"\n            for char in remove_chars: \n                filename = filename.replace(char, \"\")\n            #filename = filename[:31]\n            ihv_dict[filename] = row['Inhaltsverzeichnis-Link'][0]\n        else: \n            for im, ihv_link in enumerate(list(row['Inhaltsverzeichnis-Link'][0].split(\";\"))): \n                filename = f\"{i}.{im+1}_{row['', 'Nachname']}_{row['Erscheinungsdatum', '']}_{row['Titel', '']}\"\n                remove_chars = \"[/:*?\\\"<>|],'- \"\n                for char in remove_chars: \n                    filename = filename.replace(char, \"\")\n                #filename = filename[:31]\n                ihv_dict[filename] = ihv_link\n\nprint('Es wurden ', len(ihv_dict), ' Links fürs Herunterladen gefunden.')\n'''",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "'''\nsave_to_path = None\n#save_to_path = r\"C:/Benutzer\"\ni = 0\nfor filename, link in ihv_dict.items(): \n    try: \n        response = requests.get(link)\n        if not save_to_path: \n            complete_path = os.path.expanduser(f\"~/downloads/{filename}.pdf\")\n        else: \n            complete_path = os.path.join(f\"{save_to_path}/{filename}.pdf\")\n        with open(complete_path, 'wb') as f: \n            f.write(response.content)\n        i += 1\n    except: \n        continue\n\nprint('Es wurden ', i, ' von ', len(ihv_dict), ' Links heruntergeladen.')\n'''",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "<a id='nachnutzung'></a>\n### Nachnutzung der Ergebnisse",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "- **Erstellung einer Bibliographie (= Liste von Referenzen)**\n\nSie möchten alle Referenzdaten der Bücher mit einem bestimmten Suchbegriff (Autor, Titel, Verlag, Publikationsort, Erscheinungsdatum) herunterladen, z.B. für die Erstellung einer Bibliographie einer (akademischen) **Forschungsarbeit** oder zur Literaturauswertung zu Beginn einer Forschungsarbeit. Dazu braucht es Rohdaten, um diese einem gewissen Zitationsstil anpassen zu können. Auch Literaturverwaltungssysteme wie Citavi, Endnote, Mendeley und Zotero können mit den Daten eingepflegt werden.  \n- **Zugriff auf Swisscovery-Links für Bestellungen**\n\nIn der Ergebnisdatei findet sich mitunter eine Spalte \"Swisscovery-Link\". Der Nutzer kann die [Swisscovery-Links](https://uzb.swisscovery.slsp.ch/discovery/search?vid=41SLSP_UZB:UZB) nutzen, um **Bücher vorbestellen bzw. reservieren** zu können. Dank den Swisscovery-Links können die Medien auf der Hauptseite der Bibliothek und weitere dazugehörige Informationen ausfindig gemacht werden; deren Standort (Bibliothek, Geschoss, Magazin), Signatur und Ausleihinformationen sind auf Swisscovery verfügbar. Die Swisscovery-Seite bietet auch noch weitere Filtermöglichkeiten an zur Einschränkung der Suche.  \n\n- **Überblick über alle Zusammenfassungen**\n\nIn der Ergebnisdatei gibt es eine Spalte, die \"Zusammenfassung\" heisst. Der Nutzer kann die Zusammenfassungen/Abstracts eines Suchbegriffs dadurch einsehen. Eine Zusammenfassung bietet einen Überblick über das entsprechende Buch. Sie kann dazu dienen, zu verstehen, ob das Buch wirklich zum **Forschungsthema** passt, oder ob man es verwerfen kann.    \n- **Inhaltsverzeichnisse als PDF-Dateien**\n\nDie Ergebnisdatei beinhaltet die Spalte \"Inhaltsverzeichnis-Link\". Der Nutzer kann dank den Links alle Inhaltsverzeichnisse als PDF herunterladen, damit man bei mehreren Autoren eines Buches z.B. die **Autorenliste** im Inhaltsverzeichnis überblicken kann.  Mit der Spalte \"Inhaltsverzeichnis-Links\" können die Links zu den PDF-Inhaltsverzeichnissen mit ein paar Zeilen Code direkt lokal auf den Computer heruntergeladen werden. Die Dateinamen der PDF-Inhaltsverzeichnisse sind nach Index, Nachname des Autors, Erscheinungsjahr und abgekürzter Titel des Medium benannt.  \n\n- **Meta-Statistiken**\n\nDer Nutzer kann die detaillierten Angaben in der Ergebnisdatei als Suchresultat des Bibliothekskatalogs dazu nutzen, um damit  **statistische Analysen** der bibliographischen (Meta-)Daten durchzuführen. Z.B. kann nach Anzahl, Auflage, Sprache, Genre, Epoche und Thema analytisch erhoben werden. Man kann die Suchresultate mit geeigneten statistischen Diagrammen visuell anschaulich auswerten wie zum Beispiel Balken-, Kuchen- oder Liniendiagramme.  \n\n- **Einbettung in Websites oder Web-Apps**\n\nDer Nutzer möchte das Suchresultat im JSON-Format in Websites oder Web-Apps einbetten.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Mit den oben vorgeführten Schritten dieses Notebooks können Sie eine einfache Suchabfrage des SLSP-Bibliothekskatalogs durchführen, um den Bibliothekskatalog optimal zu nutzen und Medien zu finden, die Ihrem spezifischen Forschungsinteresse entsprechen. Dieses Jupyter Notebook bietet dazu eine optimierte und effiziente Möglichkeit, nach Medien zu suchen, welche die individuellen Anforderungen erfüllen. \n\n*Für weitere Fragen und Feedback wenden Sie sich bitte an Linda Samsinger, Metadaten-Expertin an der Zentralbibliothek Zürich, unter linda.samsinger@zb.uzh.ch.* ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "**Zentralbibliothek Zürch** | Kantons-, Stadt- und Universitätsbibliothek \n\nFolgen Sie uns auf sozialen Medien:\n\n<nav>\n<a href=\"https://www.facebook.com/Zentralbibliothek.Zuerich/?locale=de_DE\">Facebook</a> |\n<a href=\"https://twitter.com/zbzuerich?lang=de\">Twitter</a> |\n<a href=\"https://www.youtube.com/channel/UCVLFfTBvY89xBI_rEBgmdvQ\">YouTube</a> |\n<a href=\"https://www.instagram.com/zentralbibliothek_zuerich/?hl=de\">Instagram</a> |\n<a href=\"https://ch.linkedin.com/company/zentralbibliothek-z%C3%BCrich\">LinkedIn</a>  \n</nav>",
      "metadata": {}
    }
  ]
}